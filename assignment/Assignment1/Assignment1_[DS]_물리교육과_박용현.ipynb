{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 1: Raw Data Parsing, Processing, and Applying Regular Expressions\n",
    "## 개요\n",
    "- json 형식의 파일에서 필요한 정보를 추출\n",
    "- 추출된 텍스트 내용을 다양한 모듈과 방법을 사용하여 한국어 preprocessing을 수행\n",
    "- 정제된 데이터에서 정규표현식을 사용하여 제시된 결과 도출\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내용\n",
    "- 첨부된 NIRW1900000011.json 파일은 국립국어원의 총 367개의 뉴스 기사 코퍼스 중 1개의 파일. \n",
    "- 뉴스기사의 json파일을 프로세싱 해서 필요한 뉴스기사 (form) 정보만을 추출\n",
    "- 추출된 텍스트에는 ‘, ’, ◇, ‘, ”,  ’, ', ·, \\“, ·, △, ●,  , ■, (, ), \\\", >>, `, /, -,∼,=,ㆍ<,>, .,?, !,【,】, …, ◆,% 등의 불필요한 심볼, 기호, 공백 등이 있을 수 있음\n",
    "- 정규표현을 사용하기 쉽게 가능한 선처리 및 정규화 진행\n",
    "- 제시된 정규표현으로 그 결과를 도출하고 출력하는 프로그래밍\n",
    "- 정규표현은 한글의 자모를 분리하거나, 유니코드의 글자 배열 방식을 활용하여 수식을 만들어 처리하는 등 여러 가지 방법 및 가능성이 존재. 여러분들의 창의적인 방법을 기대함!\n",
    "- 한국어 자소 분해 및 결합 등과 관련한 설명과 자료는 강의자료에 있는 NLP Modules and Tools나 [이 블로그 참조](https://m.blog.naver.com/myincizor/221631254811). 한글 관련 라이브러리가 많으니 참조하길.\n",
    "- 개인적으로 하거나 최대 두명까지 그룹 허용. \n",
    "- 이 노트북 화일에 이름을 변경하여 작업하고 제출. 제출시 화일명을 Assignment1_[DS또는 CL]_학과_이름.ipynb\n",
    "- 마감: 9월 23일 23시 59분 59초! \n",
    "- 이 시각 이후에는 ETL에 업로드 차단됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신문 말뭉치 구조 \n",
    "\n",
    "```python\n",
    "{\n",
    "    \"id\": \"NLRW1900000151\",\n",
    "    \"metadata\": {\n",
    "        \"title\": \"국립국어원 신문 말뭉치 NLRW1900000151\",\n",
    "        \"creator\": \"국립국어원\",\n",
    "        \"distributor\": \"국립국어원\",\n",
    "        \"year\": \"2019\",\n",
    "        \"category\": \"신문 > 지역 종합지\",\n",
    "        \"annotation_level\": [\n",
    "            \"원시\"\n",
    "        ],\n",
    "        \"sampling\": \"부분 추출 - 임의 추출\"\n",
    "    },\n",
    "    \"document\": [\n",
    "        {\n",
    "            \"id\": \"NLRW1900000151.1\",\n",
    "            \"metadata\": {\n",
    "                \"title\": \"영남일보 2017년 기사\",\n",
    "                \"author\": \"구경모기자\",\n",
    "                \"publisher\": \"영남일보\",\n",
    "                \"date\": \"20170105\",\n",
    "                \"topic\": \"사회\",\n",
    "                \"original_topic\": \"정치\"\n",
    "            },\n",
    "            \"paragraph\": [\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.1\",\n",
    "                    \"form\": \"軍 “北 김정은 제거 특수여단 올해 창설”\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.2\",\n",
    "                    \"form\": \"북한의 핵·대량살상무기(WMD) 위협에 대비한 특수임무여단이 창설된다. 국방부는 4일 황교안 대통령 권한대\n",
    "행 에게 새해 첫 업무보고를 하는 자리에서 “유사시 북한 전쟁지도부를 제거하고 기능을 마비시키는 임무를 수행하는 특수임무여단을 올해\n",
    " 조기에 창설하는 계획을 국방개혁기본계획에 반영했다”며 이같이 밝혔다. ☞15면에 관련기사\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.3\",\n",
    "                    \"form\": \"국방부에 따르면 특수임무여단은 한반도 유사시 평양에 진입해 핵무기 발사명령 권한을 가지고 있는 김정은\n",
    " 북한 노동당 위원장을 비롯한 전쟁지도부를 제거하고, 전쟁지휘시설을 마비시키는 임무를 수행한다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.4\",\n",
    "                    \"form\": \"북한의 핵 능력과 관련해서는 “북한은 강력한 국제제재와 압박에도 핵·미사일 능력 고도화에 혈안이 되어 \n",
    "있으며, 통전(통일전선) 책동 강화와 함께 전략·전술적 도발을 감행할 가능성이 있다\\\"고 밝혔다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.5\",\n",
    "                    \"form\": \"군 당국은 지난해부터 특수임무여단이 사용할 개인화기와 통신장비 등을 마련해 왔다. 특히 특수임무여단의\n",
    " 침투를 돕기 위해 특수장비로 개조된 헬기와 수송기 등 항공전력도 중·장기적으로 도입할 계획이다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.6\",\n",
    "                    \"form\": \"국방부 관계자는 “특수임무여단 창설은 당초 2019년으로 예정했는데 2년 앞당기게 됐다”며 “여단은 육군 특\n",
    "수전사령부 예하의 일부 부대를 재편성해 만들어진다. 북한 수뇌부를 비롯해 핵시설, 미사일 기지, 대량살상무기 관련 시설 등이 목표”라\n",
    "고 말했다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.1.7\",\n",
    "                    \"form\": \"한편 황교안 권한대행은 이날부터 11일까지 ‘2017년 정부 부처 업무보고’를 받는다. 정부 각 부처가 새해 \n",
    "국정의 기본 그림을 보고하는 업무보고는 박근혜 대통령의 직무 정지로 황 권한대행이 하게 됐다.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"NLRW1900000151.2\",\n",
    "            \"metadata\": {\n",
    "                \"title\": \"영남일보 2017년 기사\",\n",
    "                \"author\": \"최수경기자\",\n",
    "                \"publisher\": \"영남일보\",\n",
    "                \"date\": \"20170105\",\n",
    "                \"topic\": \"정치\",\n",
    "                \"original_topic\": \"정치\"\n",
    "            },\n",
    "            \"paragraph\": [\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.2.1\",\n",
    "                    \"form\": \"權 시장 “엑스코線 올해 예타 신청”\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.2.2\",\n",
    "                    \"form\": \"권영진 대구시장은 4일 “대구도시철도 엑스코선(동대구역~경북대~산격동 시청별관~종합유통단지~검단들) 연\n",
    "결사업을 올해 예비타당성조사대상사업으로 정부에 신청하겠다”고 밝혔다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.2.3\",\n",
    "                    \"form\": \"권 시장은 이날 대구시청에서 열린 신년 기자회견에서 “엑스코선 연결사업은 과거 지하화로 추진했을 땐 경\n",
    "제성이 떨어져 무산됐다. 이 부분은 지금도 마찬가지라고 본다”면서 “하지만 도시철도 3호선(모노레일)이나 트램(노면전차) 방식으로 추진\n",
    "하면 경제성이 있을 것”이라고 강조했다. 이어 “앞으로 개발될 검단들까지 노선이 연장되면, 사업방식에 따라서 경제성이 더 나올 가능성\n",
    "이 있다”면서 “올해 예타신청을 계기로, 가급적 2021년 세계가스총회 때 개통했으면 좋겠다. 다소 어려움이 있겠지만 최대한 빨리 추진하\n",
    "겠다”고 덧붙였다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.2.4\",\n",
    "                    \"form\": \"대구도시철도 ‘엑스코선 구간’은 다른 구간에 비해 유동인구가 많아 이미 오래전부터 도시철도 건설 필요성\n",
    "이 꾸준히 제기돼 온 곳이다. 특히 이 구간엔 경북대·영진전문대 등의 대학들도 자리잡고 있어 학생과 교직원들의 학교 접근성이 크게 향\n",
    "상될 것으로 보인다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"NLRW1900000151.2.5\",\n",
    "                    \"form\": \"아울러 권 시장은 창업생태계조성 차원에서 지역 창업기업에 투자할 엔젤투자자(민간투자자) 육성에 적극 \n",
    "나서겠다는 의지도 피력했다. 우선 이스라엘의 대표적 벤처캐피털이자 스타트업 지원펀드인 ‘요즈마 그룹’과의 협업을 추진한다. 대구창조\n",
    "경제혁신센터를 통해 기업창업을 진두지휘하는 삼성측에 대해선 “자체 벤처육성 프로그램인 C-Lab(Creative Lab)에 있는 기업에만 투자하\n",
    "지 말고, 앞으론 창업보육기업을 만드는 데도 직접 참여했으면 한다”고 말했다.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규표현을 사용하여\n",
    "1. **글자별로** (가, 갃, 마.. 등) 받침이 없는 글자를 찾아 빈도 순으로 출력\n",
    "2. **글자별로** 받침이 'ㄲ ㄳ ㄵ ㄶ ㄺ ㄻ ㄼ ㄽ ㄾ ㄿ ㅀ ㅄ ㅆ' 인 겹받침인 글자를 찾아 빈도순으로 출력\n",
    "(#주의 이 곁받침 글자들은 별도의 글자로 코드값이 할당되어 있음. 'ㄳ'은'ㄱㅅ'등의 연쇄가 아님. 정규표현식 사용에 주의 \n",
    "3. **어절별로** 'ㅅ' 으로 시작하고 'ㅇ'으로 끝나는 단어, 가령 '사랑' 을 찾고 그 빈도 순으로 출력\n",
    "4. 받침이 없는 글자로 이루어진 어절을 찾아 (예: 가자)그 빈도 순으로 출력\n",
    "5. 정규표현을 위해서는 자소분리된 단위를 사용하지만 그 결과를 출력할 때는 자소가 결합된 형태로 출력해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전략\n",
    "### 1, 2 : 글자별 규칙 적용\n",
    "regular expression 이 overlap 을 처리하기에 적합하지 않다는 사실을 알고 (1) 데이터로부터 음절 단위로 추출한 뒤, (2) 해당 음절이 규칙을 만족하는지 조사했습니다. 규칙은 다음과 같습니다.\n",
    "1. 모음으로 시작하고, 자음으로 끝나는 음절\n",
    "2. 쌍자음으로 끝나는 음절\n",
    "\n",
    "### 3, 4 : 어절별 규칙 적용\n",
    "수업시간에 여러 학생분들께서 어절에 대한 질문을 해주셨지만, 정확한 기준을 이해하지 못해서 띄어쓰기와 특수 기호만을 기준으로 했습니다. 다만, 혹시 모른다는 생각에 띄어쓰기와 특수기호를 기준으로 구분한 답과 한글만을 어절로 취급한 답 2개를 제출했습니다. 전처리 이후 적용한 규칙은 다음과 같습니다.\n",
    "\n",
    "3. ㅅ 으로 시작하고, ㅇ 으로 끝나는 어절\n",
    "4. 각 음절이 자음으로 시작하고 모음으로 끝나는 어절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 불러들어와 json파일을 파싱하여 필요한 텍스트를 추출\n",
    "import json\n",
    "\n",
    "with open('NIRW1900000011.json', 'r', encoding = 'utf-8') as news_json:\n",
    "    news = json.load(news_json)\n",
    "\n",
    "news_document = news['document']\n",
    "news_list = []\n",
    "\n",
    "for idx in range(len(news_document)):\n",
    "    news = news_document[idx]\n",
    "    for par_idx in range(len(news['paragraph'])):\n",
    "        paragraph = news['paragraph'][par_idx]\n",
    "        news_list.append(paragraph['form'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 파일들 import\n",
    "from jamo import h2j, j2hcj\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from unicode import join_jamos\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''필요한 함수들'''\n",
    "# split string by syllable unit\n",
    "def split_by_syllable(news_list):\n",
    "    news_syllable = []\n",
    "    \n",
    "    for news in news_list:\n",
    "        for syllable in news:\n",
    "            news_syllable.append(syllable)\n",
    "            \n",
    "    return (news_syllable)\n",
    "\n",
    "# split string by segment\n",
    "def split_by_segment(news_list):\n",
    "    news_segment = []\n",
    "    \n",
    "    for news in news_list:\n",
    "        segment = re.split('[ \\W]+', news)\n",
    "        not_korean_indexs = [index for index, element in enumerate(segment) if element == ''] # find index of '' in list\n",
    "        for idx in reversed(not_korean_indexs): del segment[idx] # delete '' in list\n",
    "        news_segment += segment\n",
    "            \n",
    "    return (news_segment)\n",
    "\n",
    "# split string by segment\n",
    "def split_by_segment_hangul(news_list):\n",
    "    news_segment = []\n",
    "    \n",
    "    for news in news_list:\n",
    "        segment = re.split('[^가-힣]+', news)\n",
    "        not_korean_indexs = [index for index, element in enumerate(segment) if element == ''] # find index of '' in list\n",
    "        for idx in reversed(not_korean_indexs): del segment[idx] # delete '' in list\n",
    "        news_segment += segment\n",
    "            \n",
    "    return (news_segment)\n",
    "    \n",
    "# judge whether the processed data satisfy the rule\n",
    "def find_solution(news_list_processed, rule):\n",
    "    result = []\n",
    "    \n",
    "    for nl in tqdm(news_list_processed):\n",
    "        nl_jm = j2hcj(h2j(nl))\n",
    "        nl_found_jm = re.findall(rule, nl_jm)\n",
    "\n",
    "        if len(nl_found_jm) != 0:\n",
    "            for item in nl_found_jm:\n",
    "                result.append(join_jamos(item))\n",
    "    \n",
    "    return (result)\n",
    "\n",
    "# judge whether the processed data satisfy the rule; only for problem 4\n",
    "def find_solution_prob4(news_list_segment, rule):\n",
    "    result = []\n",
    "    \n",
    "    for nl in tqdm(news_list_segment):\n",
    "        is_satisfy_rule = True\n",
    "        for syllable in nl:\n",
    "            nl_syllable_jm = j2hcj(h2j(syllable))\n",
    "            nl_found_jm = re.findall(rule, nl_syllable_jm)\n",
    "\n",
    "            # check whether segment un-satify the rule\n",
    "            if len(nl_found_jm) == 0:\n",
    "                is_satisfy_rule = False\n",
    "                                \n",
    "        if is_satisfy_rule:\n",
    "            result.append(nl)\n",
    "        \n",
    "    return (result)\n",
    "\n",
    "# print list sorted by order\n",
    "def sort_by_frequency(data_list):\n",
    "    data_count = dict(collections.Counter(data_list))\n",
    "    data_sorted = {k: v for k, v in sorted(data_count.items(), key = lambda item: item[1], reverse = True)}\n",
    "    \n",
    "    return (data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rules\n",
    "consonant = '[^ㅏ-ㅣ]'\n",
    "vowel = '[ㅏ-ㅣ]'\n",
    "double_consonant = '[ㄲㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄㅆ]'\n",
    "\n",
    "rule_problem_1 = '^' + consonant + vowel + '$'\n",
    "rule_problem_2 = '.*' + double_consonant + '$'\n",
    "rule_problem_3 = '^' + 'ㅅ' + '.*' + 'ㅇ' + '$'\n",
    "rule_problem_4 = '^' + consonant + vowel + '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1544410/1544410 [00:19<00:00, 78511.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 1544410/1544410 [00:14<00:00, 108896.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 364072/364072 [00:09<00:00, 39293.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 364072/364072 [00:12<00:00, 30323.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# solve_problem\n",
    "news_list_syllable = split_by_syllable(news_list)\n",
    "news_list_segment  = split_by_segment(news_list)\n",
    "\n",
    "answer_problem_1 = find_solution(news_list_syllable, rule_problem_1)\n",
    "answer_problem_2 = find_solution(news_list_syllable, rule_problem_2)\n",
    "answer_problem_3 = find_solution(news_list_segment, rule_problem_3)\n",
    "answer_problem_4 = find_solution_prob4(news_list_segment, rule_problem_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 349656/349656 [00:09<00:00, 38099.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 349656/349656 [00:11<00:00, 30588.88it/s]\n"
     ]
    }
   ],
   "source": [
    "news_list_segment_hangul  = split_by_segment_hangul(news_list)\n",
    "answer_problem_3_hangul = find_solution(news_list_segment_hangul, rule_problem_3)\n",
    "answer_problem_4_hangul = find_solution_prob4(news_list_segment_hangul, rule_problem_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제된 데이터에 대한 전체 토큰수, 글자 수 등의 기본적인 통계작업 및 출력\n",
    "answer_problem_1_sort_dict = sort_by_frequency(answer_problem_1)\n",
    "answer_problem_2_sort_dict = sort_by_frequency(answer_problem_2)\n",
    "answer_problem_3_sort_dict = sort_by_frequency(answer_problem_3)\n",
    "answer_problem_4_sort_dict = sort_by_frequency(answer_problem_4)\n",
    "answer_problem_3_hangul_sort_dict = sort_by_frequency(answer_problem_3_hangul)\n",
    "answer_problem_4_hangul_sort_dict = sort_by_frequency(answer_problem_4_hangul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 공백, 특수기호만을 활용한 전처리에만 포함된 어절들 ----\n",
      "problem_3 : ['삼일PwC컨설팅', '신SW상품대상']\n",
      "problem_4 : []\n"
     ]
    }
   ],
   "source": [
    "# 전처리로 인해 달라진 결과 예시\n",
    "diff_3 = []\n",
    "diff_4 = []\n",
    "for key in answer_problem_3_sort_dict.keys():\n",
    "    if key not in answer_problem_3_hangul_sort_dict.keys():\n",
    "            diff_3.append(key)\n",
    "            \n",
    "for key in answer_problem_4_sort_dict.keys():\n",
    "    if key not in answer_problem_4_hangul_sort_dict.keys():\n",
    "            diff_4.append(key)\n",
    "            \n",
    "print('---- 공백, 특수기호만을 활용한 전처리에만 포함된 어절들 ----')\n",
    "print('problem_3 : {}'.format(diff_3))\n",
    "print('problem_4 : {}'.format(diff_4)) # 받침이 없는 음절만을 포함하므로 (즉, 한글) 없는 것이 정상이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'시장': 421, '사장': 147, '삼성': 135, '성장': 86, '사용': 72, '상생': 59, '성능': 44, '사실상': 42, '생산성': 41, '성공': 37, '선정': 32, '사상': 31, '상황': 28, '신재생': 25, '소형': 19, '신흥': 17, '생성': 17, '수익성': 16, '상용': 16, '수행': 16, '수정': 15, '상승': 15, '상당': 15, '시청': 13, '산업용': 13, '시행': 13, '수직형': 13, '세계시장': 12, '쇼핑': 12, '신뢰성': 12, '수상': 11, '사용량': 11, '신청': 11, '서류전형': 11, '수량': 10, '실행': 9, '사업부장': 9, '신시장': 9, '성': 9, '스캐닝': 9, '스마트폰용': 8, '사업장': 8, '식량': 8, '소량': 8, '수익형': 8, '삼성동': 7, '실증': 7, '신흥시장': 7, '실감형': 7, '신성장': 7, '산정': 7, '상향': 7, '설정': 7, '신종': 7, '송': 7, '선행': 6, '신경': 6, '색상': 6, '신규시장': 6, '수송': 6, '생산량': 6, '소장': 6, '신한은행': 6, '시동': 6, '상호운용성': 6, '수강': 6, '생명': 5, '신생': 5, '실효성': 5, '실무형': 5, '시간당': 5, '수동': 5, '사업용': 5, '서명': 5, '신용보증': 4, '시공': 4, '상': 4, '세상': 4, '손상': 4, '사행성': 4, '신명': 4, '신형': 3, '사용자환경': 3, '손목시계형': 3, '시장성': 3, '성당': 3, '소통': 3, '산업은행': 3, '소방': 3, '센터장': 3, '슬림형': 3, '설령': 3, '스태킹': 3, '사항': 3, '식당': 3, '실장': 3, '시행령': 3, '스토리텔링': 3, '상암동': 3, '선형': 3, '삼일PwC컨설팅': 3, '스트리밍': 3, '심기창': 3, '사랑': 3, '생방송': 2, '센싱': 2, '상호작용': 2, '사내방송': 2, '수출시장': 2, '시장상황': 2, '상장': 2, '소등': 2, '스팸성': 2, '선도형': 2, '시내망': 2, '사용자요청': 2, '심장': 2, '쉐이핑': 2, '사무용': 2, '생태환경': 2, '수입시장': 2, '상업용': 2, '신규지정': 2, '생활밀접형': 2, '소모량': 2, '식물성': 2, '스피커용': 2, '소생': 2, '생산공장': 2, '신용': 2, '시스템당': 2, '삼성생명': 2, '순환형': 2, '시장동향': 2, '수출망': 2, '시정': 2, '소비자용': 2, '수출형': 2, '상호인정': 2, '설계인증': 2, '생산공정': 2, '서버용': 2, '쇼핑맞짱': 2, '서비스팀장': 2, '산업공정': 2, '서버당': 2, '스피드경영': 2, '수평형': 2, '신호등': 2, '실정': 2, '소송': 2, '사회안전망': 2, '사회성': 2, '손해배상': 2, '사이버쇼핑': 2, '시프팅': 2, '수혜대상': 2, '스탠드형': 2, '숙성': 2, '설치비용': 2, '설치가능': 2, '실종': 2, '사양': 2, '수주량': 2, '시행현황': 2, '생계형': 2, '선택형': 2, '성추행': 2, '석방': 2, '실습형': 2, '신공정': 2, '석사과정': 2, '성재생': 2, '수송용': 2, '스위칭': 2, '수입차량': 2, '수십만명': 1, '슈팅': 1, '심명종': 1, '성인병': 1, '사용편의성': 1, '시장환경': 1, '선물세트용': 1, '산학협력단장': 1, '선진국형': 1, '시스템상': 1, '신상': 1, '실용성': 1, '수학여행': 1, '시정전망': 1, '성행': 1, '사회갈등': 1, '서초동': 1, '수성': 1, '생활정보형': 1, '선행대응': 1, '상호접속협정': 1, '사민당': 1, '세율조정': 1, '서비스역량': 1, '스팸전송': 1, '서방': 1, '시범적용': 1, '선양': 1, '소방방재청': 1, '사무총장': 1, '실상': 1, '속칭': 1, '순환이용': 1, '수강생': 1, '생체이식용': 1, '수장': 1, '시장검증': 1, '서방형': 1, '사명': 1, '사용성': 1, '세로형': 1, '선진시장': 1, '성장시장': 1, '색재현성': 1, '수입담당': 1, '산학장학생': 1, '스키폴공항': 1, '사진촬영': 1, '사업본부장': 1, '사리공': 1, '사리병': 1, '시중': 1, '수령': 1, '서버상': 1, '사회공헌활동': 1, '시군구청': 1, '서울시청': 1, '수행역량': 1, '소켓형': 1, '성산정공': 1, '세이빙': 1, '순방': 1, '서비스업종': 1, '사업자당': 1, '삽입형': 1, '성능시험인증': 1, '시픽스이미징': 1, '신상흥': 1, '상품명': 1, '실천매장': 1, '상품보충': 1, '사망': 1, '스틱형': 1, '소득세법상': 1, '수평': 1, '석준형': 1, '상상': 1, '실적증명': 1, '성산동': 1, '서석장': 1, '생화학적산소요구량': 1, '스트롱': 1, '서비스경쟁': 1, '산티에고은행': 1, '세정': 1, '세정기능': 1, '새글요청': 1, '소재형': 1, '소비량': 1, '심사과정': 1, '사업단장': 1, '산업동향': 1, '산업중': 1, '소셜네트워킹': 1, '실시간성': 1, '세계교역량': 1, '순정': 1, '수출용': 1, '세탁소용': 1, '삼정': 1, '사출성형': 1, '삼중': 1, '사업행정': 1, '사이버전쟁': 1, '세미나장': 1, '서울특별시장상': 1, '사냥': 1, '실속형': 1, '수영장': 1, '수용성': 1, '스포츠마케팅': 1, '셋톱박스용': 1, '산업포장': 1, '성낙영': 1, '시스템명': 1, '소용량': 1, '세계환경': 1, '색보정': 1, '사업진행': 1, '사격장': 1, '사정': 1, '생활형': 1, '수직운동': 1, '수원사업장': 1, '선정성': 1, '서울광장': 1, '식약청': 1, '스케줄링': 1, '센터용': 1, '실용': 1, '소매상': 1, '성인용': 1, '산업환경': 1, '시효성': 1, '서울디지털산업단지경영자협의회장': 1, '슬라이딩': 1, '시스템운영': 1, '생고방': 1, '생체용': 1, '시장현황': 1, '소양': 1, '슬라이드형': 1, '수밀성': 1, '수급안정': 1, '시각장애인용': 1, '시트로앵': 1, '설치량': 1, '신재생에너지사업본부장': 1, '시행하나태양광': 1, '실행용': 1, '상영': 1, '선박조립용': 1, '수출입은행': 1, '실적당': 1, '스마트그리드용': 1, '사서용': 1, '생산용': 1, '스케쥴링': 1, '실내용': 1, '생산성향성': 1, '사업비용': 1, '상업송장': 1, '신용보강': 1, '승계대상': 1, '산업기술진흥원장': 1, '사업내용': 1, '서울청': 1, '식품의약품안전청': 1, '세계은행': 1, '신SW상품대상': 1, '실용위성': 1, '신경통': 1, '산행': 1, '생산계획스케쥴링': 1, '수도용': 1, '수명': 1, '신항': 1, '선박금융': 1, '성과측정': 1, '수용': 1, '산업진흥': 1, '시중은행': 1, '상생경영': 1, '시상': 1, '스트트리밍': 1, '선생': 1, '서비스용': 1, '서버유형': 1, '생': 1, '수요반응': 1, '심층': 1, '실정상': 1, '수험시장': 1, '성향': 1, '서버기반컴퓨팅': 1, '세우회빌딩': 1, '사무국장': 1, '성장가능성': 1, '시장성장': 1, '선장': 1, '수신환경': 1, '상반기중': 1, '수소저장용': 1, '신호처리용': 1, '샘플링': 1, '시어터용': 1, '세입세출외현금지급명령': 1, '신흥국시장': 1}\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 예시\n",
    "print(answer_problem_3_sort_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
