{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목표\n",
    "\n",
    "- csv 파일을 읽어서 torchtext를 사용하여 데이터를 신경망에 입력가능한 꼴로 바꾸기\n",
    "(Field, Iterator, train,test, evaluation and prediction)\n",
    "- base line으로 Naive Bayes classification 구현\n",
    "- 한국어 데이터 전처리를 위한 함수를 만들고 이를 torchtext에 통합하기 \n",
    "- 제시된 여러 모델을 사용하여(transformers 제외) 성능을 향상 시키기\n",
    "- training, evaluation 한 것을 test 데이터에 적용하여 성능을 보이기.\n",
    "- predict를 사용하여 제시된 기사들의 분류 결과를 보이기\n",
    "\n",
    "- 참고 사이트\n",
    "    - https://pytorch.org/text/\n",
    "    - http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "    - https://github.com/pytorch/text\n",
    "    - https://github.com/bentrevett/pytorch-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내용\n",
    "\n",
    "- 첨부된 BalancedNewsCorpus_train.csv, BalancedNewsCorpus_test.csv는 국어원 뉴스 자료에서 9개 분야의 신문별 균형을 맞춘 자료로, 학습용 9,000개 시험용 1800 자료가 있는 파일이다.\n",
    "- 이 파일을 가지고 https://github.com/bentrevett/pytorch-sentiment-analysis 에 있는 pytorch sentiment analysis의 방법을 따라 한국어 뉴스기사 분류기를 만들어라\n",
    "- 한국어 선처리를 위해 함수를 만들어 이를 torchText에 통합하여 사용. preprocessing은 다양한 방법으로 가능함.\n",
    "- baseline으로 Naive Bayes를 사용하고 Neural Network를 사용하는 모델이 얼마나 더 성능의 향상을 이루는지 보여라..\n",
    "- https://github.com/bentrevett/pytorch-sentiment-analysis 에 제시된 방법 중 가장 성능이 좋은 방법을 사용할 수 있음. **단 이 과제에서는 외부 임베딩과, transformers를 사용하는 방법은 적용하지 말것**\n",
    "- Evaluation, Test 성능을 정리하고, 이렇게 학습한 모델로 제시된 User Input에서 제시된 문장의 출력과 정답을 비교 분석하라.\n",
    "- 화일 이름은 MidTermProject_DS(or CL)_Group X\n",
    "- 조원 이름 명시\n",
    "- torchtext version 0.9\n",
    "- ipynb와 data파일이 같이 들어있는 걸 생각하고 돌려라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General\n",
    "- 마감: 10월 21일 목요일 오후 12시!\n",
    "- 이 노트북 화일에 이름을 변경하여 작업하고 제출. 제출시 화일명을 Assignment3_[DS또는 CL]_학과_이름.ipynb\n",
    "- 화일에 각 조원 이름 명시\n",
    "- 코드, 또는 셀 마다 자세한 설명 요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 구현한 시스템의 성능을 정리 (프리프로세싱 방법, 사용한 모델, 테스트 성능 등)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed TorchText ver :  0.9.1\n",
      "Current WD :  c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3\n",
      "Current OS :  win32\n",
      "['BalancedNewsCorpus_train.csv', 'BalancedNewsCorpus_test.csv']\n"
     ]
    }
   ],
   "source": [
    "## Your code starts\n",
    "\n",
    "import os, re, zipfile, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchtext\n",
    "\n",
    "print('Installed TorchText ver : ', torchtext.__version__)\n",
    "\n",
    "from sys import platform\n",
    "print('Current WD : ', os.getcwd())\n",
    "print('Current OS : ', platform)\n",
    "if 'win32' in platform:\n",
    "    from eunjeon import Mecab\n",
    "else:\n",
    "    from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "zip_read = zipfile.ZipFile('BalancedNewsCorpusShuffled.zip', mode='r')\n",
    "print(zip_read.namelist()) ## Inspect the contents of single_file.zip\n",
    "\n",
    "data = {}\n",
    "for file in zip_read.namelist():\n",
    "    if 'train' in file:\n",
    "        zip_read.extract(file) ## Extract a single file from the zip file\n",
    "        data['train'] = pd.read_csv(file)\n",
    "    else:\n",
    "        zip_read.extract(file) ## Extract a single file from the zip file\n",
    "        data['test'] = pd.read_csv(file)\n",
    "\n",
    "zip_read.close() ## Close the archive releasing it from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>NewsPaper</th>\n",
       "      <th>Topic</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLRW1900000141</td>\n",
       "      <td>20170324</td>\n",
       "      <td>부산일보</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>&lt;p&gt; 야구 종가, 마침내 정상에 서다 &lt;/p&gt; &lt;p&gt; '야구 종가' 미국이 푸에르...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NPRW1900000003</td>\n",
       "      <td>20110209</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>&lt;p&gt; 외통위 27명중 15명 \"FTA 추가협상안만 처리\" &lt;/p&gt; &lt;p&gt; 국회 외...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLRW1900000144</td>\n",
       "      <td>20100406</td>\n",
       "      <td>영남일보</td>\n",
       "      <td>사회</td>\n",
       "      <td>&lt;p&gt; 한나라 \"地選후보, 희망연대 당원 구함\" 공천변수 작용 주목 &lt;/p&gt; &lt;p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLRW1900000064</td>\n",
       "      <td>20100804</td>\n",
       "      <td>광주매일신문</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>&lt;p&gt; 모처럼 살아난 ‘CK포’ 7타점 합작 &lt;/p&gt; &lt;p&gt; KIA 12 3 LG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLRW1900000070</td>\n",
       "      <td>20160615</td>\n",
       "      <td>광주매일신문</td>\n",
       "      <td>문화</td>\n",
       "      <td>&lt;p&gt; 亞문화전당서 동방의 등불 만나다 &lt;/p&gt; &lt;p&gt; “일찍이 아시아의 황금 시기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>NWRW1900000006</td>\n",
       "      <td>20141114</td>\n",
       "      <td>조선일보사</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 내가 구매한 영화, 출근길의 오빠도 방에 있는 엄마도 보네? &lt;/p&gt; &lt;p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>NIRW1900000022</td>\n",
       "      <td>20101217</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>연예</td>\n",
       "      <td>&lt;p&gt; 꽃보다 예쁜 터치 선웅의 여장, 이게 바로 ‘안산 F4’ &lt;/p&gt; &lt;p&gt; 수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>NLRW1900000092</td>\n",
       "      <td>20180131</td>\n",
       "      <td>국제신문</td>\n",
       "      <td>사회</td>\n",
       "      <td>&lt;p&gt; “어머니 빨리 쾌차하세요”…밀양참사 후 더 깊어진 고부애 &lt;/p&gt; &lt;p&gt; -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>NLRW1900000103</td>\n",
       "      <td>20090206</td>\n",
       "      <td>대전일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 엑스포공원 ‘HD 드라마 타운’ 성공하려면… &lt;/p&gt; &lt;p&gt; 대전 엑스포 과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>NLRW1900000083</td>\n",
       "      <td>20090117</td>\n",
       "      <td>국제신문</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>&lt;p&gt; 호주오픈 테니스 19일 개막..우승 향방 불투명 &lt;/p&gt; &lt;p&gt; 2009시즌...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      date NewsPaper  Topic  \\\n",
       "0     NLRW1900000141  20170324      부산일보    스포츠   \n",
       "1     NPRW1900000003  20110209   한국경제신문사     정치   \n",
       "2     NLRW1900000144  20100406      영남일보     사회   \n",
       "3     NLRW1900000064  20100804    광주매일신문    스포츠   \n",
       "4     NLRW1900000070  20160615    광주매일신문     문화   \n",
       "...              ...       ...       ...    ...   \n",
       "8995  NWRW1900000006  20141114     조선일보사  IT/과학   \n",
       "8996  NIRW1900000022  20101217      노컷뉴스     연예   \n",
       "8997  NLRW1900000092  20180131      국제신문     사회   \n",
       "8998  NLRW1900000103  20090206      대전일보  IT/과학   \n",
       "8999  NLRW1900000083  20090117      국제신문    스포츠   \n",
       "\n",
       "                                                   News  \n",
       "0     <p> 야구 종가, 마침내 정상에 서다 </p> <p> '야구 종가' 미국이 푸에르...  \n",
       "1     <p> 외통위 27명중 15명 \"FTA 추가협상안만 처리\" </p> <p> 국회 외...  \n",
       "2     <p> 한나라 \"地選후보, 희망연대 당원 구함\" 공천변수 작용 주목 </p> <p>...  \n",
       "3     <p> 모처럼 살아난 ‘CK포’ 7타점 합작 </p> <p> KIA 12 3 LG ...  \n",
       "4     <p> 亞문화전당서 동방의 등불 만나다 </p> <p> “일찍이 아시아의 황금 시기...  \n",
       "...                                                 ...  \n",
       "8995  <p> 내가 구매한 영화, 출근길의 오빠도 방에 있는 엄마도 보네? </p> <p>...  \n",
       "8996  <p> 꽃보다 예쁜 터치 선웅의 여장, 이게 바로 ‘안산 F4’ </p> <p> 수...  \n",
       "8997  <p> “어머니 빨리 쾌차하세요”…밀양참사 후 더 깊어진 고부애 </p> <p> -...  \n",
       "8998  <p> 엑스포공원 ‘HD 드라마 타운’ 성공하려면… </p> <p> 대전 엑스포 과...  \n",
       "8999  <p> 호주오픈 테니스 19일 개막..우승 향방 불투명 </p> <p> 2009시즌...  \n",
       "\n",
       "[9000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>NewsPaper</th>\n",
       "      <th>Topic</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLRW1900000024</td>\n",
       "      <td>20120209</td>\n",
       "      <td>경기일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 인터넷 게임 족쇄에 도내 업체도 ‘덜덜’ &lt;/p&gt; &lt;p&gt; 道ㆍ업체 \"긍정적인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLRW1900000029</td>\n",
       "      <td>20171018</td>\n",
       "      <td>경기일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 삼성전자, UN에 삼성만의 특화된 생태 보전 활동 자랑하다생물다양성 보존활동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLRW1900000029</td>\n",
       "      <td>20170920</td>\n",
       "      <td>경기일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 지자체의 ‘카카오채널’, 도민들 관심 부족으로 폐쇄되거나 운영 부실 &lt;/p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLRW1900000025</td>\n",
       "      <td>20130218</td>\n",
       "      <td>경기일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 돈만 잡아먹는 홈페이지, 과감하게 ‘로그아웃’ &lt;/p&gt; &lt;p&gt; 경기도가 연간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLRW1900000028</td>\n",
       "      <td>20160314</td>\n",
       "      <td>경기일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>&lt;p&gt; 콘텐츠기업 대상 ‘부천 클러스터’ 입주사 모집 &lt;/p&gt; &lt;p&gt; 경기콘텐츠진흥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>NPRW1900000004</td>\n",
       "      <td>20120903</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>&lt;p&gt; 안철수, 독자출마로 가나…정치권 배제한채 대권 행보 &lt;/p&gt; &lt;p&gt; 안철수 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>NPRW1900000001</td>\n",
       "      <td>20091116</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>&lt;p&gt; 예산심의 또 표류…서민·저소득층 울린다 &lt;/p&gt; &lt;p&gt; 국회의 예산심의가 표...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>NPRW1900000005</td>\n",
       "      <td>20130221</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>&lt;p&gt; \"퇴직금 7000만원은 로비 대가\" 제기, 커지는 김병관 의혹…朴의 선택은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>NPRW1900000004</td>\n",
       "      <td>20120706</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>&lt;p&gt; \"국회의원ㆍ장관 겸직 금지하면 임명권자 인재풀 좁아져 반대\" &lt;/p&gt; &lt;p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>NPRW1900000005</td>\n",
       "      <td>20130124</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>&lt;p&gt; 민주 \"또 반대하기는 좀…\" &lt;/p&gt; &lt;p&gt; 국무총리실은 박근혜 대통령 당선...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      date NewsPaper  Topic  \\\n",
       "0     NLRW1900000024  20120209      경기일보  IT/과학   \n",
       "1     NLRW1900000029  20171018      경기일보  IT/과학   \n",
       "2     NLRW1900000029  20170920      경기일보  IT/과학   \n",
       "3     NLRW1900000025  20130218      경기일보  IT/과학   \n",
       "4     NLRW1900000028  20160314      경기일보  IT/과학   \n",
       "...              ...       ...       ...    ...   \n",
       "1795  NPRW1900000004  20120903   한국경제신문사     정치   \n",
       "1796  NPRW1900000001  20091116   한국경제신문사     정치   \n",
       "1797  NPRW1900000005  20130221   한국경제신문사     정치   \n",
       "1798  NPRW1900000004  20120706   한국경제신문사     정치   \n",
       "1799  NPRW1900000005  20130124   한국경제신문사     정치   \n",
       "\n",
       "                                                   News  \n",
       "0     <p> 인터넷 게임 족쇄에 도내 업체도 ‘덜덜’ </p> <p> 道ㆍ업체 \"긍정적인...  \n",
       "1     <p> 삼성전자, UN에 삼성만의 특화된 생태 보전 활동 자랑하다생물다양성 보존활동...  \n",
       "2     <p> 지자체의 ‘카카오채널’, 도민들 관심 부족으로 폐쇄되거나 운영 부실 </p>...  \n",
       "3     <p> 돈만 잡아먹는 홈페이지, 과감하게 ‘로그아웃’ </p> <p> 경기도가 연간...  \n",
       "4     <p> 콘텐츠기업 대상 ‘부천 클러스터’ 입주사 모집 </p> <p> 경기콘텐츠진흥...  \n",
       "...                                                 ...  \n",
       "1795  <p> 안철수, 독자출마로 가나…정치권 배제한채 대권 행보 </p> <p> 안철수 ...  \n",
       "1796  <p> 예산심의 또 표류…서민·저소득층 울린다 </p> <p> 국회의 예산심의가 표...  \n",
       "1797  <p> \"퇴직금 7000만원은 로비 대가\" 제기, 커지는 김병관 의혹…朴의 선택은 ...  \n",
       "1798  <p> \"국회의원ㆍ장관 겸직 금지하면 임명권자 인재풀 좁아져 반대\" </p> <p>...  \n",
       "1799  <p> 민주 \"또 반대하기는 좀…\" </p> <p> 국무총리실은 박근혜 대통령 당선...  \n",
       "\n",
       "[1800 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>NewsPaper</th>\n",
       "      <th>Topic</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLRW1900000141</td>\n",
       "      <td>20170324</td>\n",
       "      <td>부산일보</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>야구 종가  마침내 정상에 서다           야구 종가  미국이 푸에르...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NPRW1900000003</td>\n",
       "      <td>20110209</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>외통위   명중   명      추가협상안만 처리           국회 외...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLRW1900000144</td>\n",
       "      <td>20100406</td>\n",
       "      <td>영남일보</td>\n",
       "      <td>사회</td>\n",
       "      <td>한나라    후보  희망연대 당원 구함  공천변수 작용 주목         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLRW1900000064</td>\n",
       "      <td>20100804</td>\n",
       "      <td>광주매일신문</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>모처럼 살아난    포   타점 합작                      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLRW1900000070</td>\n",
       "      <td>20160615</td>\n",
       "      <td>광주매일신문</td>\n",
       "      <td>문화</td>\n",
       "      <td>문화전당서 동방의 등불 만나다           일찍이 아시아의 황금 시기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>NWRW1900000006</td>\n",
       "      <td>20141114</td>\n",
       "      <td>조선일보사</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>내가 구매한 영화  출근길의 오빠도 방에 있는 엄마도 보네          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>NIRW1900000022</td>\n",
       "      <td>20101217</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>연예</td>\n",
       "      <td>꽃보다 예쁜 터치 선웅의 여장  이게 바로  안산              수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>NLRW1900000092</td>\n",
       "      <td>20180131</td>\n",
       "      <td>국제신문</td>\n",
       "      <td>사회</td>\n",
       "      <td>어머니 빨리 쾌차하세요  밀양참사 후 더 깊어진 고부애           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>NLRW1900000103</td>\n",
       "      <td>20090206</td>\n",
       "      <td>대전일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>엑스포공원     드라마 타운  성공하려면           대전 엑스포 과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>NLRW1900000083</td>\n",
       "      <td>20090117</td>\n",
       "      <td>국제신문</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>호주오픈 테니스   일 개막  우승 향방 불투명              시즌...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      date NewsPaper  Topic  \\\n",
       "0     NLRW1900000141  20170324      부산일보    스포츠   \n",
       "1     NPRW1900000003  20110209   한국경제신문사     정치   \n",
       "2     NLRW1900000144  20100406      영남일보     사회   \n",
       "3     NLRW1900000064  20100804    광주매일신문    스포츠   \n",
       "4     NLRW1900000070  20160615    광주매일신문     문화   \n",
       "...              ...       ...       ...    ...   \n",
       "8995  NWRW1900000006  20141114     조선일보사  IT/과학   \n",
       "8996  NIRW1900000022  20101217      노컷뉴스     연예   \n",
       "8997  NLRW1900000092  20180131      국제신문     사회   \n",
       "8998  NLRW1900000103  20090206      대전일보  IT/과학   \n",
       "8999  NLRW1900000083  20090117      국제신문    스포츠   \n",
       "\n",
       "                                                   News  \n",
       "0         야구 종가  마침내 정상에 서다           야구 종가  미국이 푸에르...  \n",
       "1         외통위   명중   명      추가협상안만 처리           국회 외...  \n",
       "2         한나라    후보  희망연대 당원 구함  공천변수 작용 주목         ...  \n",
       "3         모처럼 살아난    포   타점 합작                      ...  \n",
       "4          문화전당서 동방의 등불 만나다           일찍이 아시아의 황금 시기...  \n",
       "...                                                 ...  \n",
       "8995      내가 구매한 영화  출근길의 오빠도 방에 있는 엄마도 보네          ...  \n",
       "8996      꽃보다 예쁜 터치 선웅의 여장  이게 바로  안산              수...  \n",
       "8997       어머니 빨리 쾌차하세요  밀양참사 후 더 깊어진 고부애           ...  \n",
       "8998      엑스포공원     드라마 타운  성공하려면           대전 엑스포 과...  \n",
       "8999      호주오픈 테니스   일 개막  우승 향방 불투명              시즌...  \n",
       "\n",
       "[9000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## preprocessing\n",
    "def cleaning_txt(input):\n",
    "    output = re.sub('[^ㄱ-ㅣ가-힣]', ' ', input)\n",
    "    return output\n",
    "\n",
    "# data['train'].info()\n",
    "for key in data.keys():\n",
    "    data[key]['News'] = data[key]['News'].apply(lambda x: re.sub('[^ㄱ-ㅣ가-힣]', ' ', str(x)))\n",
    "\n",
    "data['train'].dropna(inplace= True)\n",
    "data['test'].dropna(inplace= True)\n",
    "\n",
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련자료 :  (7200,)\n",
      "validation자료 :  (1800,)\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "# https://www.geeksforgeeks.org/applying-multinomial-naive-bayes-to-nlp-problems/\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "'''\n",
    "1. 데이터 준비, 2. 전처리, 3. 훈련자료 훈련/validation으로 나누기\n",
    "'''\n",
    "stop_word = ''\n",
    "def lemmatization(input, SW = stop_word):\n",
    "    output = [x for x in input if x not in SW]\n",
    "    return output\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    data['train']['News'], data['train']['Topic'], test_size = 0.2\n",
    ")\n",
    "\n",
    "print('훈련자료 : ', X_train.shape)\n",
    "print('validation자료 : ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7200x1762 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1584130 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4.Vectorize \n",
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(analyzer = lemmatization) # 앞서 정의한 함수를 활용해서 벡터화 \n",
    "X_train = count_vec.fit_transform(X_train) # fit_transform 결과 덮어쓰기 \n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = count_vec.transform(X_valid) # 절대 fit_transform을 하면 안됨. \n",
    "# CountVectorizer는 이미 훈련자료에 fit 되어 있기 때문에\n",
    "# validation자료에 대해서 fit_transform하면 차원오류가 생김\n",
    "# X_test = count_vec.transform(data['test']['News'])  # 이 단계에서 훈련자료에 transform하면 안됨\n",
    "# Full Train set에 대해 적용된게 아니므로, \n",
    "\n",
    "'''\n",
    "5. Model Building\n",
    "'''\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 1762) (1800, 1762)\n",
      "Train & Validation :  0.686\n",
      "Full Train & Test :  0.704\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "6. Calculate Accuracy using validation data\n",
    "7. Comparing with Full Train and Test\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(X_train.shape, X_valid.shape)\n",
    "\n",
    "pred_val = clf.predict(X_valid)\n",
    "print('Train & Validation : ', round(accuracy_score(pred_val, y_valid), 3))\n",
    "\n",
    "\n",
    "'''\n",
    "7. Comparing with Full Train and Test\n",
    "'''\n",
    "count_vec = CountVectorizer(analyzer = lemmatization)\n",
    "X_fTrain = count_vec.fit_transform(data['train']['News'])\n",
    "y_ftrain = data['train']['Topic']\n",
    "\n",
    "X_test = count_vec.transform(data['test']['News'])\n",
    "y_test = data['test']['Topic']\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_fTrain, y_ftrain)\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "print('Full Train & Test : ', round(accuracy_score(pred_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your choice of Neural Network Model\n",
    "import torch\n",
    "seed = 0\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "label = {'IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8}\n",
    "\n",
    "def label_encoder(topic, label=label):\n",
    "    output = label[topic]\n",
    "    return int(output)\n",
    "\n",
    "data['train']['Topic_encd'] = data['train']['Topic'].map(label_encoder)\n",
    "data['test']['Topic_encd'] = data['test']['Topic'].map(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>NewsPaper</th>\n",
       "      <th>Topic</th>\n",
       "      <th>News</th>\n",
       "      <th>Topic_encd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLRW1900000141</td>\n",
       "      <td>20170324</td>\n",
       "      <td>부산일보</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>야구 종가  마침내 정상에 서다           야구 종가  미국이 푸에르...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NPRW1900000003</td>\n",
       "      <td>20110209</td>\n",
       "      <td>한국경제신문사</td>\n",
       "      <td>정치</td>\n",
       "      <td>외통위   명중   명      추가협상안만 처리           국회 외...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLRW1900000144</td>\n",
       "      <td>20100406</td>\n",
       "      <td>영남일보</td>\n",
       "      <td>사회</td>\n",
       "      <td>한나라    후보  희망연대 당원 구함  공천변수 작용 주목         ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLRW1900000064</td>\n",
       "      <td>20100804</td>\n",
       "      <td>광주매일신문</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>모처럼 살아난    포   타점 합작                      ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLRW1900000070</td>\n",
       "      <td>20160615</td>\n",
       "      <td>광주매일신문</td>\n",
       "      <td>문화</td>\n",
       "      <td>문화전당서 동방의 등불 만나다           일찍이 아시아의 황금 시기...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>NWRW1900000006</td>\n",
       "      <td>20141114</td>\n",
       "      <td>조선일보사</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>내가 구매한 영화  출근길의 오빠도 방에 있는 엄마도 보네          ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>NIRW1900000022</td>\n",
       "      <td>20101217</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>연예</td>\n",
       "      <td>꽃보다 예쁜 터치 선웅의 여장  이게 바로  안산              수...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>NLRW1900000092</td>\n",
       "      <td>20180131</td>\n",
       "      <td>국제신문</td>\n",
       "      <td>사회</td>\n",
       "      <td>어머니 빨리 쾌차하세요  밀양참사 후 더 깊어진 고부애           ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>NLRW1900000103</td>\n",
       "      <td>20090206</td>\n",
       "      <td>대전일보</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>엑스포공원     드라마 타운  성공하려면           대전 엑스포 과...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>NLRW1900000083</td>\n",
       "      <td>20090117</td>\n",
       "      <td>국제신문</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>호주오픈 테니스   일 개막  우승 향방 불투명              시즌...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      date NewsPaper  Topic  \\\n",
       "0     NLRW1900000141  20170324      부산일보    스포츠   \n",
       "1     NPRW1900000003  20110209   한국경제신문사     정치   \n",
       "2     NLRW1900000144  20100406      영남일보     사회   \n",
       "3     NLRW1900000064  20100804    광주매일신문    스포츠   \n",
       "4     NLRW1900000070  20160615    광주매일신문     문화   \n",
       "...              ...       ...       ...    ...   \n",
       "8995  NWRW1900000006  20141114     조선일보사  IT/과학   \n",
       "8996  NIRW1900000022  20101217      노컷뉴스     연예   \n",
       "8997  NLRW1900000092  20180131      국제신문     사회   \n",
       "8998  NLRW1900000103  20090206      대전일보  IT/과학   \n",
       "8999  NLRW1900000083  20090117      국제신문    스포츠   \n",
       "\n",
       "                                                   News  Topic_encd  \n",
       "0         야구 종가  마침내 정상에 서다           야구 종가  미국이 푸에르...           6  \n",
       "1         외통위   명중   명      추가협상안만 처리           국회 외...           8  \n",
       "2         한나라    후보  희망연대 당원 구함  공천변수 작용 주목         ...           4  \n",
       "3         모처럼 살아난    포   타점 합작                      ...           6  \n",
       "4          문화전당서 동방의 등불 만나다           일찍이 아시아의 황금 시기...           2  \n",
       "...                                                 ...         ...  \n",
       "8995      내가 구매한 영화  출근길의 오빠도 방에 있는 엄마도 보네          ...           0  \n",
       "8996      꽃보다 예쁜 터치 선웅의 여장  이게 바로  안산              수...           7  \n",
       "8997       어머니 빨리 쾌차하세요  밀양참사 후 더 깊어진 고부애           ...           4  \n",
       "8998      엑스포공원     드라마 타운  성공하려면           대전 엑스포 과...           0  \n",
       "8999      호주오픈 테니스   일 개막  우승 향방 불투명              시즌...           6  \n",
       "\n",
       "[9000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:  (7200, 2)\n",
      "Valid Size:  (1800, 2)\n",
      "Test Size:  (1800, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(\n",
    "    data['train'], train_size = 0.8, \n",
    "    stratify = data['train']['Topic_encd']\n",
    ")\n",
    "\n",
    "df_train = df_train[['News', 'Topic_encd']]\n",
    "df_valid = df_valid[['News', 'Topic_encd']]\n",
    "df_test = data['test'][['News', 'Topic_encd']]\n",
    "\n",
    "print('Train Size: ',df_train.shape) \n",
    "print('Valid Size: ',df_valid.shape)\n",
    "print('Test Size: ',df_test.shape)\n",
    "\n",
    "\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "df_valid.to_csv('valid.csv', index=False)\n",
    "df_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Topic_encd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>한      년내 공산품 관세 없앤다          한국과 유럽연합    ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>중국경제둔화대책          중국의 경제둔화가 빠르게 진행하자 중국이 하...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>분당서울대병원 김나영 교수  신간 출간          분당서울대학교병원 소...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>홍  계파활동땐 공천 배제   말 끝나자마자 거센 역풍          새로...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>이달  개 업체 신규 상장  코넥스 시장 중소기업 전용 주식시장  활기 찾을...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   News  Topic_encd\n",
       "6157      한      년내 공산품 관세 없앤다          한국과 유럽연합    ...           5\n",
       "4084      중국경제둔화대책          중국의 경제둔화가 빠르게 진행하자 중국이 하...           1\n",
       "4609      분당서울대병원 김나영 교수  신간 출간          분당서울대학교병원 소...           3\n",
       "559       홍  계파활동땐 공천 배제   말 끝나자마자 거센 역풍          새로...           8\n",
       "3104      이달  개 업체 신규 상장  코넥스 시장 중소기업 전용 주식시장  활기 찾을...           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('News', <torchtext.legacy.data.field.Field at 0x19d628c57c0>),\n",
       " ('Topic_encd', <torchtext.legacy.data.field.Field at 0x19d628c5490>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn # Neural Network\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator # Preliminiaries\n",
    "\n",
    "'''1. Field'''\n",
    "LABEL = Field(dtype=torch.float, \n",
    "                batch_first = True)\n",
    "TEXT = Field(tokenize=mecab.morphs,  # 형태소 분석기는 Mecab\n",
    "            include_lengths=True, \n",
    "            sequential = True,\n",
    "            batch_first = True) # 신경망에 입력되는 텐서의 첫번째 값\n",
    "fields = [('News', TEXT), ('Topic_encd', LABEL)]\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'News': ['한', '년', '내', '공산품', '관세', '없앤다', '한국', '과', '유럽', '연합', '이', '년', '안', '에', '자동차', '등', '대부분', '공산품', '에', '대한', '관세', '를', '없애', '기', '로', '했', '다', '관세', '혜택', '적용', '대상', '을', '판별', '하', '는', '기준', '인', '원산지', '문제', '에', '대해서', '도', '양쪽', '의', '의견', '차이', '가', '상당히', '좁혀졌', '다', '일', '외교통상부', '와', '지식', '경제', '부', '관계자', '들', '의', '말', '을', '종합', '하', '면', '한', '유럽연합', '자유', '무역', '협정', '차', '협상', '을', '앞두', '고', '양쪽', '은', '공산품', '의', '관세', '철폐', '시기', '와', '원산지', '문제', '는', '물론', '서비스', '와', '비관세', '장벽', '분야', '에서', '도', '상당', '부분', '의견', '접근', '을', '이뤘', '다', '이', '에', '따라', '한', '유럽', '연합', '에', '프티', '에', '이', '타결', '은', '초읽기', '에', '들어갔', '다', '우선', '유럽연합', '은', '한국', '공산품', '에', '대해', '년', '안', '에', '품목', '수', '기준', '년', '안', '에', '관세', '를', '없앤다', '우리', '나라', '도', '유럽', '연합', '공산품', '에', '대해', '년', '안', '에', '의', '관세', '를', '철폐', '하', '고', '년', '안', '에', '모든', '품목', '으로', '이', '를', '확대', '하', '기', '로', '했', '다', '다만', '우리', '나라', '는', '일부', '민감', '공산품', '에', '대해서', '는', '관세', '철폐', '시한', '을', '년', '으로', '늘리', '는', '것', '에', '유럽연합', '과', '합의', '했', '다', '특히', '양쪽', '의', '큰', '쟁점', '이', '었', '던', '자동차', '관세', '와', '관련', '해', '배기량', '이상', '중대', '형', '은', '년', '미만', '소형', '은', '년', '에', '걸쳐', '균등', '비율', '로', '관세', '를', '완전', '철폐', '하', '기', '로', '했', '다', '자동차', '관세', '는', '현재', '우리', '나라', '가', '유럽연합', '이', '의', '세율', '을', '적용', '하', '고', '있', '다', '유럽', '연합', '이', '줄기차', '게', '요구', '해', '온', '자동차', '기술', '표준', '문제', '는', '우리', '쪽', '이', '양보', '했', '다', '벤츠', '와', '베', '엠', '베', '등', '유럽', '산', '자동차', '가', '한국', '의', '규제', '에', '맞춰', '별도', '옵션', '을', '갖추', '지', '않', '고', '도', '팔', '수', '있', '게', '된', '셈', '이', '다', '이번', '협상', '의', '최대', '쟁점', '으로', '꼽혔', '던', '공산품', '의', '원산지', '인정', '문제', '에', '대해선', '완제품', '기준', '수준', '의', '부가', '가치', '가', '역내', '에서', '발생', '하', '면', '한국', '유럽', '산', '으로', '인정', '하', '기', '로', '했', '다', '애초', '우리', '나라', '는', '한국', '산', '인정', '비율', '을', '수준', '으로', '제시', '했으며', '유럽연합', '은', '최소', '를', '주장', '해', '양쪽', '이', '팽팽히', '맞서', '왔', '다', '개성', '공단', '제품', '의', '한국', '산', '인정', '문제', '는', '한', '미', '에', '프티', '에', '이', '방식', '을', '차용', '하', '기', '로', '했', '다', '한', '미', '에', '프티', '에이', '에서', '는', '협정', '발효', '년', '뒤', '에', '한반도', '역외', '가공', '지역', '위원회', '를', '열', '어', '한반도', '비핵화', '진전', '등', '일정', '요건', '을', '갖추', '면', '개성', '공단', '제품', '을', '한국', '산', '으로', '인정', '하', '기', '로', '했', '다', '서비스', '분야', '에서', '는', '한', '미', '에', '프티', '에', '이', '수준', '으로', '시장', '을', '개방', '하', '되', '하수도', '위탁', '처리', '와', '위성', '서비스', '전용', '회선', '접근', '에서', '는', '개방', '폭', '을', '더', '확대', '하', '기', '로', '한', '것', '으로', '알려졌', '다', '양쪽', '은', '차', '협상', '에서', '잠정', '타결', '을', '선언', '한', '뒤', '다음', '달', '일', '주요', '국', '정상', '회의', '가', '열리', '는', '영국', '런던', '에서', '통상', '장관', '회담', '을', '따로', '열', '어', '한', '유럽', '연합', '에', '프티', '에', '이', '협상', '의', '최종', '타결', '을', '선언', '할', '계획', '이', '다'], 'Topic_encd': ['5']}\n"
     ]
    }
   ],
   "source": [
    "'''2. Iterators'''\n",
    "train, valid, test = TabularDataset.splits(path=os.getcwd(), train='train.csv', validation='valid.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "print(vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이', 108474),\n",
       " ('다', 108055),\n",
       " ('는', 102978),\n",
       " ('을', 102489),\n",
       " ('의', 73085),\n",
       " ('에', 70011),\n",
       " ('하', 59915),\n",
       " ('를', 59115),\n",
       " ('은', 58160),\n",
       " ('고', 53545),\n",
       " ('가', 40083),\n",
       " ('있', 38960),\n",
       " ('한', 38864),\n",
       " ('으로', 33897),\n",
       " ('했', 30016),\n",
       " ('에서', 29138),\n",
       " ('도', 27682),\n",
       " ('로', 26216),\n",
       " ('들', 25083),\n",
       " ('과', 23364)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''4. Vocab'''\n",
    "TEXT.build_vocab(train, min_freq=3) # 훈련자료에 대해서만 보캡 빌드\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "TEXT.vocab.freqs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34110"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '이', '다', '는', '을', '의', '에', '하', '를']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.iterator.Iterator at 0x19d628c52b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''3. Iterator'''\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 1.1 Using BucketIterator\n",
    "# # arg1. sort_key : 우리가 배치 크기를 비슷하게 만들어주기 위해서 문서의 텍스트 길이를 고려하는 것\n",
    "# # arg2. BucketIterator : padding의 사용 수를 최소화 시켜줌\n",
    "# train_iter = BucketIterator(train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.News), # x['News']로 사용하면 TypeError 나옴\n",
    "#                             device=device, sort=True, sort_within_batch=True)\n",
    "# valid_iter = BucketIterator(valid, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.News),\n",
    "#                             device=device, sort=True, sort_within_batch=True)\n",
    "# test_iter = BucketIterator(test, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.News),\n",
    "#                             device=device, sort=True, sort_within_batch=True)\n",
    "\n",
    "\n",
    "# 1.2 Using BucketIterator\n",
    "# train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "#         (train, valid, test), batch_size=BATCH_SIZE,\n",
    "#         shuffle=True, repeat=False)\n",
    "\n",
    "\n",
    "# 2. Using Iterator\n",
    "from torchtext.legacy.data import Iterator\n",
    "train_iter = Iterator(dataset=train, batch_size = BATCH_SIZE)\n",
    "valid_iter = Iterator(dataset=valid, batch_size = BATCH_SIZE)\n",
    "test_iter = Iterator(dataset=test, batch_size = BATCH_SIZE)\n",
    "          \n",
    "train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iter) == df_train.shape[0] / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 32]\n",
      "\t[.News]:('[torch.LongTensor of size 32x596]', '[torch.LongTensor of size 32]')\n",
      "\t[.Topic_encd]:[torch.FloatTensor of size 32x1]\n",
      "<class 'torchtext.legacy.data.batch.Batch'>\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_iter):\n",
    "    if idx == 0:\n",
    "        print(batch)\n",
    "        print(type(batch))\n",
    "        print(len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "for idx, (labels, titletext) in enumerate(train_iter):\n",
    "    if idx == 1:\n",
    "        print(titletext)\n",
    "        # print(len(titletext))\n",
    "        print(type(titletext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> something1에 대하여\n",
      "(tensor([[18745,  3627,   493,  ...,     1,     1,     1],\n",
      "        [ 3599,   213,   272,  ...,     1,     1,     1],\n",
      "        [15875,  1968,  2398,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [ 3856,   197,   319,  ...,     1,     1,     1],\n",
      "        [ 1708,  3857,  1242,  ...,     1,     1,     1],\n",
      "        [10371,  2933,   236,  ...,     1,     1,     1]]), tensor([396, 557, 520, 504, 301, 511, 564, 540, 495, 329, 555, 493, 420, 534,\n",
      "        369, 499, 523, 543, 464, 568, 510, 542, 354, 536, 338, 382, 538, 452,\n",
      "        490, 533, 375, 332]))\n",
      "2\n",
      "torch.Size([32, 568])\n",
      "torch.Size([32])\n",
      "\n",
      ">>>>>>> something2에 대하여\n",
      "tensor([[ 2.],\n",
      "        [ 3.],\n",
      "        [ 6.],\n",
      "        [ 2.],\n",
      "        [ 9.],\n",
      "        [ 7.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 7.],\n",
      "        [ 9.],\n",
      "        [10.],\n",
      "        [ 2.],\n",
      "        [ 8.],\n",
      "        [ 6.],\n",
      "        [ 9.],\n",
      "        [ 3.],\n",
      "        [10.],\n",
      "        [10.],\n",
      "        [ 7.],\n",
      "        [ 4.],\n",
      "        [ 4.],\n",
      "        [ 7.],\n",
      "        [ 9.],\n",
      "        [ 7.],\n",
      "        [ 9.],\n",
      "        [ 2.],\n",
      "        [ 4.],\n",
      "        [ 2.],\n",
      "        [ 8.],\n",
      "        [ 5.],\n",
      "        [ 4.],\n",
      "        [ 9.]])\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "for idx, ((something1, something2), _) in enumerate(train_iter):\n",
    "    if idx == 0:\n",
    "        print('>>>>>>> something1에 대하여')\n",
    "        print(something1)\n",
    "        print(len(something1))\n",
    "        print(something1[0].shape)\n",
    "        print(something1[1].shape)\n",
    "        print('\\n>>>>>>> something2에 대하여')\n",
    "        print(something2)\n",
    "        print(len(something2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_iter 안에 들어있는 것\n",
    "    - 1번째 인덱스\n",
    "        - tensor represent document\n",
    "        - batch size\n",
    "    - 2번째 인덱스\n",
    "        - batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, dimension=128):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), \n",
    "                                        # 11\n",
    "                                        300\n",
    "                                        )\n",
    "        self.dimension = dimension\n",
    "        self.lstm = nn.LSTM(input_size=300,\n",
    "                            hidden_size=dimension,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(2*dimension, 1)\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        packed_input = pack_padded_sequence(text_emb, \n",
    "                                    text_len.cpu(), #specify cpu option \n",
    "                                    batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, \n",
    "                                # lengths = seq_lens.cpu(),\n",
    "                                batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
    "        out_reverse = output[:, 0, self.dimension:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = torch.sigmoid(text_fea)\n",
    "\n",
    "        return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064cc35bb05340958877a5f340f8352b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch >>>> :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [112/2250], Train Loss: -308.3734, Valid Loss: -499.5066\n",
      "Model saved to ==> c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3/model.pt\n",
      "Model saved to ==> c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3/metrics.pt\n",
      "Epoch [1/10], Step [224/2250], Train Loss: -500.9766, Valid Loss: -501.9737\n",
      "Model saved to ==> c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3/model.pt\n",
      "Model saved to ==> c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3/metrics.pt\n",
      "Epoch [2/10], Step [336/2250], Train Loss: -498.7176, Valid Loss: -501.4803\n",
      "Epoch [2/10], Step [448/2250], Train Loss: -500.1237, Valid Loss: -500.9868\n",
      "Epoch [3/10], Step [560/2250], Train Loss: -499.7432, Valid Loss: -498.6842\n",
      "Epoch [3/10], Step [672/2250], Train Loss: -500.3247, Valid Loss: -500.6579\n",
      "Epoch [4/10], Step [784/2250], Train Loss: -498.0165, Valid Loss: -501.4803\n",
      "Epoch [4/10], Step [896/2250], Train Loss: -500.2956, Valid Loss: -498.5197\n",
      "Epoch [5/10], Step [1008/2250], Train Loss: -498.6607, Valid Loss: -500.1645\n",
      "Epoch [5/10], Step [1120/2250], Train Loss: -501.9774, Valid Loss: -498.3553\n",
      "Epoch [6/10], Step [1232/2250], Train Loss: -500.2511, Valid Loss: -500.4934\n",
      "Epoch [6/10], Step [1344/2250], Train Loss: -499.8047, Valid Loss: -499.5066\n",
      "Epoch [7/10], Step [1456/2250], Train Loss: -499.5257, Valid Loss: -498.6842\n",
      "Epoch [7/10], Step [1568/2250], Train Loss: -500.0267, Valid Loss: -498.5197\n",
      "Epoch [8/10], Step [1680/2250], Train Loss: -503.0199, Valid Loss: -500.0000\n",
      "Epoch [8/10], Step [1792/2250], Train Loss: -495.8147, Valid Loss: -497.8618\n",
      "Epoch [9/10], Step [1904/2250], Train Loss: -501.6462, Valid Loss: -499.0132\n",
      "Epoch [9/10], Step [2016/2250], Train Loss: -499.9163, Valid Loss: -500.8224\n",
      "Epoch [10/10], Step [2128/2250], Train Loss: -496.9866, Valid Loss: -498.6842\n",
      "Epoch [10/10], Step [2240/2250], Train Loss: -502.2879, Valid Loss: -498.1908\n",
      "Model saved to ==> c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = os.getcwd(),\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs), desc='Epoch >>>> '):\n",
    "        for ((titletext, titletext_len), labels), _  in train_loader:           \n",
    "        # for batch in train_loader:\n",
    "            # titletext = torch.unsqueeze(titletext, 1) # titletext의 텐서 사이즈를 바꿔줘야함\n",
    "            # assert titletext.size()[1] == 1\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            titletext = titletext.to(device)\n",
    "            titletext_len = titletext_len.to(device)\n",
    "            output = model(titletext, titletext_len)\n",
    "\n",
    "            # try:\n",
    "            #   loss = criterion(output, labels)\n",
    "            # except ValueError:\n",
    "              # clear_output(wait=True)\n",
    "              # print('Output Size : ', output.size())\n",
    "              # print('Labels Size : ', labels.size())\n",
    "            output_ = torch.unsqueeze(output, 1)\n",
    "            loss = criterion(output_, labels)\n",
    "              # print('Adjusted Output Size : ', output_.size()) \n",
    "              \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                  for ((titletext, titletext_len), labels), _ in valid_loader:\n",
    "                      labels = labels.to(device)\n",
    "                      titletext = titletext.to(device)\n",
    "                      titletext_len = titletext_len.to(device)\n",
    "                      try:\n",
    "                        output = model(titletext, titletext_len)\n",
    "                      except IndexError:\n",
    "                        print(labels)\n",
    "\n",
    "                      output_ = torch.unsqueeze(output, 1)\n",
    "                      loss = criterion(output_, labels)\n",
    "                      valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = LSTM().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.3-cp38-cp38-win_amd64.whl (7.1 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-win_amd64.whl (52 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jhun1\\anaconda3\\envs\\nlp2021\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\jhun1\\anaconda3\\envs\\nlp2021\\lib\\site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jhun1\\anaconda3\\envs\\nlp2021\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.4.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\jhun1\\anaconda3\\envs\\nlp2021\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.2 matplotlib-3.4.3 pillow-8.4.0\n",
      "Model loaded from <== c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3\\metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"264.615379pt\" version=\"1.1\" viewBox=\"0 0 397.345312 264.615379\" width=\"397.345312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-10-21T06:31:06.712309</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 264.615379 \r\n",
       "L 397.345312 264.615379 \r\n",
       "L 397.345312 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 55.345313 227.059129 \r\n",
       "L 390.145312 227.059129 \r\n",
       "L 390.145312 9.619129 \r\n",
       "L 55.345313 9.619129 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m5632fc83fb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.058368\" xlink:href=\"#m5632fc83fb\" y=\"227.059129\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 500 -->\r\n",
       "      <g transform=\"translate(116.514618 241.657567)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.57238\" xlink:href=\"#m5632fc83fb\" y=\"227.059129\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 1000 -->\r\n",
       "      <g transform=\"translate(184.84738 241.657567)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"269.086392\" xlink:href=\"#m5632fc83fb\" y=\"227.059129\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 1500 -->\r\n",
       "      <g transform=\"translate(256.361392 241.657567)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"340.600405\" xlink:href=\"#m5632fc83fb\" y=\"227.059129\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 2000 -->\r\n",
       "      <g transform=\"translate(327.875405 241.657567)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_5\">\r\n",
       "     <!-- Global Steps -->\r\n",
       "     <g transform=\"translate(191.216406 255.335692)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 3809 666 \r\n",
       "L 3809 1919 \r\n",
       "L 2778 1919 \r\n",
       "L 2778 2438 \r\n",
       "L 4434 2438 \r\n",
       "L 4434 434 \r\n",
       "Q 4069 175 3628 42 \r\n",
       "Q 3188 -91 2688 -91 \r\n",
       "Q 1594 -91 976 548 \r\n",
       "Q 359 1188 359 2328 \r\n",
       "Q 359 3472 976 4111 \r\n",
       "Q 1594 4750 2688 4750 \r\n",
       "Q 3144 4750 3555 4637 \r\n",
       "Q 3966 4525 4313 4306 \r\n",
       "L 4313 3634 \r\n",
       "Q 3963 3931 3569 4081 \r\n",
       "Q 3175 4231 2741 4231 \r\n",
       "Q 1884 4231 1454 3753 \r\n",
       "Q 1025 3275 1025 2328 \r\n",
       "Q 1025 1384 1454 906 \r\n",
       "Q 1884 428 2741 428 \r\n",
       "Q 3075 428 3337 486 \r\n",
       "Q 3600 544 3809 666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-47\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1959 3097 \r\n",
       "Q 1497 3097 1228 2736 \r\n",
       "Q 959 2375 959 1747 \r\n",
       "Q 959 1119 1226 758 \r\n",
       "Q 1494 397 1959 397 \r\n",
       "Q 2419 397 2687 759 \r\n",
       "Q 2956 1122 2956 1747 \r\n",
       "Q 2956 2369 2687 2733 \r\n",
       "Q 2419 3097 1959 3097 \r\n",
       "z\r\n",
       "M 1959 3584 \r\n",
       "Q 2709 3584 3137 3096 \r\n",
       "Q 3566 2609 3566 1747 \r\n",
       "Q 3566 888 3137 398 \r\n",
       "Q 2709 -91 1959 -91 \r\n",
       "Q 1206 -91 779 398 \r\n",
       "Q 353 888 353 1747 \r\n",
       "Q 353 2609 779 3096 \r\n",
       "Q 1206 3584 1959 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3116 1747 \r\n",
       "Q 3116 2381 2855 2742 \r\n",
       "Q 2594 3103 2138 3103 \r\n",
       "Q 1681 3103 1420 2742 \r\n",
       "Q 1159 2381 1159 1747 \r\n",
       "Q 1159 1113 1420 752 \r\n",
       "Q 1681 391 2138 391 \r\n",
       "Q 2594 391 2855 752 \r\n",
       "Q 3116 1113 3116 1747 \r\n",
       "z\r\n",
       "M 1159 2969 \r\n",
       "Q 1341 3281 1617 3432 \r\n",
       "Q 1894 3584 2278 3584 \r\n",
       "Q 2916 3584 3314 3078 \r\n",
       "Q 3713 2572 3713 1747 \r\n",
       "Q 3713 922 3314 415 \r\n",
       "Q 2916 -91 2278 -91 \r\n",
       "Q 1894 -91 1617 61 \r\n",
       "Q 1341 213 1159 525 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 4863 \r\n",
       "L 1159 4863 \r\n",
       "L 1159 2969 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-62\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2194 1759 \r\n",
       "Q 1497 1759 1228 1600 \r\n",
       "Q 959 1441 959 1056 \r\n",
       "Q 959 750 1161 570 \r\n",
       "Q 1363 391 1709 391 \r\n",
       "Q 2188 391 2477 730 \r\n",
       "Q 2766 1069 2766 1631 \r\n",
       "L 2766 1759 \r\n",
       "L 2194 1759 \r\n",
       "z\r\n",
       "M 3341 1997 \r\n",
       "L 3341 0 \r\n",
       "L 2766 0 \r\n",
       "L 2766 531 \r\n",
       "Q 2569 213 2275 61 \r\n",
       "Q 1981 -91 1556 -91 \r\n",
       "Q 1019 -91 701 211 \r\n",
       "Q 384 513 384 1019 \r\n",
       "Q 384 1609 779 1909 \r\n",
       "Q 1175 2209 1959 2209 \r\n",
       "L 2766 2209 \r\n",
       "L 2766 2266 \r\n",
       "Q 2766 2663 2505 2880 \r\n",
       "Q 2244 3097 1772 3097 \r\n",
       "Q 1472 3097 1187 3025 \r\n",
       "Q 903 2953 641 2809 \r\n",
       "L 641 3341 \r\n",
       "Q 956 3463 1253 3523 \r\n",
       "Q 1550 3584 1831 3584 \r\n",
       "Q 2591 3584 2966 3190 \r\n",
       "Q 3341 2797 3341 1997 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3425 4513 \r\n",
       "L 3425 3897 \r\n",
       "Q 3066 4069 2747 4153 \r\n",
       "Q 2428 4238 2131 4238 \r\n",
       "Q 1616 4238 1336 4038 \r\n",
       "Q 1056 3838 1056 3469 \r\n",
       "Q 1056 3159 1242 3001 \r\n",
       "Q 1428 2844 1947 2747 \r\n",
       "L 2328 2669 \r\n",
       "Q 3034 2534 3370 2195 \r\n",
       "Q 3706 1856 3706 1288 \r\n",
       "Q 3706 609 3251 259 \r\n",
       "Q 2797 -91 1919 -91 \r\n",
       "Q 1588 -91 1214 -16 \r\n",
       "Q 841 59 441 206 \r\n",
       "L 441 856 \r\n",
       "Q 825 641 1194 531 \r\n",
       "Q 1563 422 1919 422 \r\n",
       "Q 2459 422 2753 634 \r\n",
       "Q 3047 847 3047 1241 \r\n",
       "Q 3047 1584 2836 1778 \r\n",
       "Q 2625 1972 2144 2069 \r\n",
       "L 1759 2144 \r\n",
       "Q 1053 2284 737 2584 \r\n",
       "Q 422 2884 422 3419 \r\n",
       "Q 422 4038 858 4394 \r\n",
       "Q 1294 4750 2059 4750 \r\n",
       "Q 2388 4750 2728 4690 \r\n",
       "Q 3069 4631 3425 4513 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1172 4494 \r\n",
       "L 1172 3500 \r\n",
       "L 2356 3500 \r\n",
       "L 2356 3053 \r\n",
       "L 1172 3053 \r\n",
       "L 1172 1153 \r\n",
       "Q 1172 725 1289 603 \r\n",
       "Q 1406 481 1766 481 \r\n",
       "L 2356 481 \r\n",
       "L 2356 0 \r\n",
       "L 1766 0 \r\n",
       "Q 1100 0 847 248 \r\n",
       "Q 594 497 594 1153 \r\n",
       "L 594 3053 \r\n",
       "L 172 3053 \r\n",
       "L 172 3500 \r\n",
       "L 594 3500 \r\n",
       "L 594 4494 \r\n",
       "L 1172 4494 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3597 1894 \r\n",
       "L 3597 1613 \r\n",
       "L 953 1613 \r\n",
       "Q 991 1019 1311 708 \r\n",
       "Q 1631 397 2203 397 \r\n",
       "Q 2534 397 2845 478 \r\n",
       "Q 3156 559 3463 722 \r\n",
       "L 3463 178 \r\n",
       "Q 3153 47 2828 -22 \r\n",
       "Q 2503 -91 2169 -91 \r\n",
       "Q 1331 -91 842 396 \r\n",
       "Q 353 884 353 1716 \r\n",
       "Q 353 2575 817 3079 \r\n",
       "Q 1281 3584 2069 3584 \r\n",
       "Q 2775 3584 3186 3129 \r\n",
       "Q 3597 2675 3597 1894 \r\n",
       "z\r\n",
       "M 3022 2063 \r\n",
       "Q 3016 2534 2758 2815 \r\n",
       "Q 2500 3097 2075 3097 \r\n",
       "Q 1594 3097 1305 2825 \r\n",
       "Q 1016 2553 972 2059 \r\n",
       "L 3022 2063 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1159 525 \r\n",
       "L 1159 -1331 \r\n",
       "L 581 -1331 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2969 \r\n",
       "Q 1341 3281 1617 3432 \r\n",
       "Q 1894 3584 2278 3584 \r\n",
       "Q 2916 3584 3314 3078 \r\n",
       "Q 3713 2572 3713 1747 \r\n",
       "Q 3713 922 3314 415 \r\n",
       "Q 2916 -91 2278 -91 \r\n",
       "Q 1894 -91 1617 61 \r\n",
       "Q 1341 213 1159 525 \r\n",
       "z\r\n",
       "M 3116 1747 \r\n",
       "Q 3116 2381 2855 2742 \r\n",
       "Q 2594 3103 2138 3103 \r\n",
       "Q 1681 3103 1420 2742 \r\n",
       "Q 1159 2381 1159 1747 \r\n",
       "Q 1159 1113 1420 752 \r\n",
       "Q 1681 391 2138 391 \r\n",
       "Q 2594 391 2855 752 \r\n",
       "Q 3116 1113 3116 1747 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2834 3397 \r\n",
       "L 2834 2853 \r\n",
       "Q 2591 2978 2328 3040 \r\n",
       "Q 2066 3103 1784 3103 \r\n",
       "Q 1356 3103 1142 2972 \r\n",
       "Q 928 2841 928 2578 \r\n",
       "Q 928 2378 1081 2264 \r\n",
       "Q 1234 2150 1697 2047 \r\n",
       "L 1894 2003 \r\n",
       "Q 2506 1872 2764 1633 \r\n",
       "Q 3022 1394 3022 966 \r\n",
       "Q 3022 478 2636 193 \r\n",
       "Q 2250 -91 1575 -91 \r\n",
       "Q 1294 -91 989 -36 \r\n",
       "Q 684 19 347 128 \r\n",
       "L 347 722 \r\n",
       "Q 666 556 975 473 \r\n",
       "Q 1284 391 1588 391 \r\n",
       "Q 1994 391 2212 530 \r\n",
       "Q 2431 669 2431 922 \r\n",
       "Q 2431 1156 2273 1281 \r\n",
       "Q 2116 1406 1581 1522 \r\n",
       "L 1381 1569 \r\n",
       "Q 847 1681 609 1914 \r\n",
       "Q 372 2147 372 2553 \r\n",
       "Q 372 3047 722 3315 \r\n",
       "Q 1072 3584 1716 3584 \r\n",
       "Q 2034 3584 2315 3537 \r\n",
       "Q 2597 3491 2834 3397 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-47\"/>\r\n",
       "      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"105.273438\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"166.455078\" xlink:href=\"#DejaVuSans-62\"/>\r\n",
       "      <use x=\"229.931641\" xlink:href=\"#DejaVuSans-61\"/>\r\n",
       "      <use x=\"291.210938\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"318.994141\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"350.78125\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      <use x=\"414.257812\" xlink:href=\"#DejaVuSans-74\"/>\r\n",
       "      <use x=\"453.466797\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"514.990234\" xlink:href=\"#DejaVuSans-70\"/>\r\n",
       "      <use x=\"578.466797\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m2192f09b78\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"214.108679\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- −500 -->\r\n",
       "      <g transform=\"translate(20.878125 217.907897)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 678 2272 \r\n",
       "L 4684 2272 \r\n",
       "L 4684 1741 \r\n",
       "L 678 1741 \r\n",
       "L 678 2272 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2212\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"188.719996\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- −475 -->\r\n",
       "      <g transform=\"translate(20.878125 192.519215)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2419 4116 \r\n",
       "L 825 1625 \r\n",
       "L 2419 1625 \r\n",
       "L 2419 4116 \r\n",
       "z\r\n",
       "M 2253 4666 \r\n",
       "L 3047 4666 \r\n",
       "L 3047 1625 \r\n",
       "L 3713 1625 \r\n",
       "L 3713 1100 \r\n",
       "L 3047 1100 \r\n",
       "L 3047 0 \r\n",
       "L 2419 0 \r\n",
       "L 2419 1100 \r\n",
       "L 313 1100 \r\n",
       "L 313 1709 \r\n",
       "L 2253 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n",
       "        <path d=\"M 525 4666 \r\n",
       "L 3525 4666 \r\n",
       "L 3525 4397 \r\n",
       "L 1831 0 \r\n",
       "L 1172 0 \r\n",
       "L 2766 4134 \r\n",
       "L 525 4134 \r\n",
       "L 525 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-37\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"163.331314\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- −450 -->\r\n",
       "      <g transform=\"translate(20.878125 167.130532)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"137.942631\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- −425 -->\r\n",
       "      <g transform=\"translate(20.878125 141.74185)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"112.553949\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- −400 -->\r\n",
       "      <g transform=\"translate(20.878125 116.353167)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"87.165266\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- −375 -->\r\n",
       "      <g transform=\"translate(20.878125 90.964485)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2597 2516 \r\n",
       "Q 3050 2419 3304 2112 \r\n",
       "Q 3559 1806 3559 1356 \r\n",
       "Q 3559 666 3084 287 \r\n",
       "Q 2609 -91 1734 -91 \r\n",
       "Q 1441 -91 1130 -33 \r\n",
       "Q 819 25 488 141 \r\n",
       "L 488 750 \r\n",
       "Q 750 597 1062 519 \r\n",
       "Q 1375 441 1716 441 \r\n",
       "Q 2309 441 2620 675 \r\n",
       "Q 2931 909 2931 1356 \r\n",
       "Q 2931 1769 2642 2001 \r\n",
       "Q 2353 2234 1838 2234 \r\n",
       "L 1294 2234 \r\n",
       "L 1294 2753 \r\n",
       "L 1863 2753 \r\n",
       "Q 2328 2753 2575 2939 \r\n",
       "Q 2822 3125 2822 3475 \r\n",
       "Q 2822 3834 2567 4026 \r\n",
       "Q 2313 4219 1838 4219 \r\n",
       "Q 1578 4219 1281 4162 \r\n",
       "Q 984 4106 628 3988 \r\n",
       "L 628 4550 \r\n",
       "Q 988 4650 1302 4700 \r\n",
       "Q 1616 4750 1894 4750 \r\n",
       "Q 2613 4750 3031 4423 \r\n",
       "Q 3450 4097 3450 3541 \r\n",
       "Q 3450 3153 3228 2886 \r\n",
       "Q 3006 2619 2597 2516 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-33\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-37\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_7\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"61.776584\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- −350 -->\r\n",
       "      <g transform=\"translate(20.878125 65.575802)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-33\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_8\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"36.387901\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- −325 -->\r\n",
       "      <g transform=\"translate(20.878125 40.18712)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-33\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_9\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.345313\" xlink:href=\"#m2192f09b78\" y=\"10.999219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_14\">\r\n",
       "      <!-- −300 -->\r\n",
       "      <g transform=\"translate(20.878125 14.798438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-33\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_15\">\r\n",
       "     <!-- Loss -->\r\n",
       "     <g transform=\"translate(14.798438 129.306317)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 628 4666 \r\n",
       "L 1259 4666 \r\n",
       "L 1259 531 \r\n",
       "L 3531 531 \r\n",
       "L 3531 0 \r\n",
       "L 628 0 \r\n",
       "L 628 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-4c\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-4c\"/>\r\n",
       "      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_14\">\r\n",
       "    <path clip-path=\"url(#p0814ca66c1)\" d=\"M 70.563494 19.502766 \r\n",
       "L 86.582633 215.100424 \r\n",
       "L 102.601772 212.806314 \r\n",
       "L 118.620911 214.234341 \r\n",
       "L 134.640049 213.84791 \r\n",
       "L 150.659188 214.43844 \r\n",
       "L 166.678327 212.094389 \r\n",
       "L 182.697466 214.408873 \r\n",
       "L 198.716604 212.748571 \r\n",
       "L 214.735743 216.116864 \r\n",
       "L 230.754882 214.363699 \r\n",
       "L 246.774021 213.91033 \r\n",
       "L 262.793159 213.626974 \r\n",
       "L 278.812298 214.135783 \r\n",
       "L 294.831437 217.175493 \r\n",
       "L 310.850576 209.858341 \r\n",
       "L 326.869714 215.780478 \r\n",
       "L 342.888853 214.023672 \r\n",
       "L 358.907992 211.048436 \r\n",
       "L 374.927131 216.432196 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_15\">\r\n",
       "    <path clip-path=\"url(#p0814ca66c1)\" d=\"M 70.563494 213.607586 \r\n",
       "L 86.582633 216.113048 \r\n",
       "L 102.601772 215.611956 \r\n",
       "L 118.620911 215.110863 \r\n",
       "L 134.640049 212.772432 \r\n",
       "L 150.659188 214.776802 \r\n",
       "L 166.678327 215.611956 \r\n",
       "L 182.697466 212.605401 \r\n",
       "L 198.716604 214.275709 \r\n",
       "L 214.735743 212.438371 \r\n",
       "L 230.754882 214.609771 \r\n",
       "L 246.774021 213.607586 \r\n",
       "L 262.793159 212.772432 \r\n",
       "L 278.812298 212.605401 \r\n",
       "L 294.831437 214.108679 \r\n",
       "L 310.850576 211.937278 \r\n",
       "L 326.869714 213.106494 \r\n",
       "L 342.888853 214.943833 \r\n",
       "L 358.907992 212.772432 \r\n",
       "L 374.927131 212.27134 \r\n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 55.345313 227.059129 \r\n",
       "L 55.345313 9.619129 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 390.145312 227.059129 \r\n",
       "L 390.145312 9.619129 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 55.345313 227.059129 \r\n",
       "L 390.145312 227.059129 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 55.345313 9.619129 \r\n",
       "L 390.145312 9.619129 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"legend_1\">\r\n",
       "    <g id=\"patch_7\">\r\n",
       "     <path d=\"M 327.046875 46.975379 \r\n",
       "L 383.145312 46.975379 \r\n",
       "Q 385.145312 46.975379 385.145312 44.975379 \r\n",
       "L 385.145312 16.619129 \r\n",
       "Q 385.145312 14.619129 383.145312 14.619129 \r\n",
       "L 327.046875 14.619129 \r\n",
       "Q 325.046875 14.619129 325.046875 16.619129 \r\n",
       "L 325.046875 44.975379 \r\n",
       "Q 325.046875 46.975379 327.046875 46.975379 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_16\">\r\n",
       "     <path d=\"M 329.046875 22.717567 \r\n",
       "L 349.046875 22.717567 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_17\"/>\r\n",
       "    <g id=\"text_16\">\r\n",
       "     <!-- Train -->\r\n",
       "     <g transform=\"translate(357.046875 26.217567)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M -19 4666 \r\n",
       "L 3928 4666 \r\n",
       "L 3928 4134 \r\n",
       "L 2272 4134 \r\n",
       "L 2272 0 \r\n",
       "L 1638 0 \r\n",
       "L 1638 4134 \r\n",
       "L -19 4134 \r\n",
       "L -19 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2631 2963 \r\n",
       "Q 2534 3019 2420 3045 \r\n",
       "Q 2306 3072 2169 3072 \r\n",
       "Q 1681 3072 1420 2755 \r\n",
       "Q 1159 2438 1159 1844 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1341 3275 1631 3429 \r\n",
       "Q 1922 3584 2338 3584 \r\n",
       "Q 2397 3584 2469 3576 \r\n",
       "Q 2541 3569 2628 3553 \r\n",
       "L 2631 2963 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 3500 \r\n",
       "L 1178 3500 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 3500 \r\n",
       "z\r\n",
       "M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 4134 \r\n",
       "L 603 4134 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3513 2113 \r\n",
       "L 3513 0 \r\n",
       "L 2938 0 \r\n",
       "L 2938 2094 \r\n",
       "Q 2938 2591 2744 2837 \r\n",
       "Q 2550 3084 2163 3084 \r\n",
       "Q 1697 3084 1428 2787 \r\n",
       "Q 1159 2491 1159 1978 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1366 3272 1645 3428 \r\n",
       "Q 1925 3584 2291 3584 \r\n",
       "Q 2894 3584 3203 3211 \r\n",
       "Q 3513 2838 3513 2113 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-72\"/>\r\n",
       "      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-61\"/>\r\n",
       "      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_18\">\r\n",
       "     <path d=\"M 329.046875 37.395692 \r\n",
       "L 349.046875 37.395692 \r\n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_19\"/>\r\n",
       "    <g id=\"text_17\">\r\n",
       "     <!-- Valid -->\r\n",
       "     <g transform=\"translate(357.046875 40.895692)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 1831 0 \r\n",
       "L 50 4666 \r\n",
       "L 709 4666 \r\n",
       "L 2188 738 \r\n",
       "L 3669 4666 \r\n",
       "L 4325 4666 \r\n",
       "L 2547 0 \r\n",
       "L 1831 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2906 2969 \r\n",
       "L 2906 4863 \r\n",
       "L 3481 4863 \r\n",
       "L 3481 0 \r\n",
       "L 2906 0 \r\n",
       "L 2906 525 \r\n",
       "Q 2725 213 2448 61 \r\n",
       "Q 2172 -91 1784 -91 \r\n",
       "Q 1150 -91 751 415 \r\n",
       "Q 353 922 353 1747 \r\n",
       "Q 353 2572 751 3078 \r\n",
       "Q 1150 3584 1784 3584 \r\n",
       "Q 2172 3584 2448 3432 \r\n",
       "Q 2725 3281 2906 2969 \r\n",
       "z\r\n",
       "M 947 1747 \r\n",
       "Q 947 1113 1208 752 \r\n",
       "Q 1469 391 1925 391 \r\n",
       "Q 2381 391 2643 752 \r\n",
       "Q 2906 1113 2906 1747 \r\n",
       "Q 2906 2381 2643 2742 \r\n",
       "Q 2381 3103 1925 3103 \r\n",
       "Q 1469 3103 1208 2742 \r\n",
       "Q 947 2381 947 1747 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-61\"/>\r\n",
       "      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"149.720703\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"177.503906\" xlink:href=\"#DejaVuSans-64\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p0814ca66c1\">\r\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"55.345313\" y=\"9.619129\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(os.path.join(os.getcwd() , 'metrics.pt'))\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== c:\\Users\\jhun1\\Dropbox\\[1]2021-2\\[2-2]NLP\\Ass3\\model.pt\n",
      "Classification Report:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# !pip install seaborn\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "def evaluate(model, test_loader, version='title', threshold=0.01):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ((titletext, titletext_len), labels), __ in test_loader:           \n",
    "            labels = labels.to(device)\n",
    "            titletext = titletext.to(device)\n",
    "            titletext_len = titletext_len.to(device)\n",
    "            output = model(titletext, titletext_len)\n",
    "\n",
    "            output = (output > threshold).int()\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    # print(classification_report(y_true, y_pred, labels=range(10), digits=4))\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "    # cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    # ax= plt.subplot()\n",
    "    # sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    # ax.set_title('Confusion Matrix')\n",
    "\n",
    "    # ax.set_xlabel('Predicted Labels')\n",
    "    # ax.set_ylabel('True Labels')\n",
    "\n",
    "    # ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    # ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    \n",
    "    \n",
    "best_model = LSTM().to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(os.path.join(os.getcwd(), 'model.pt'), best_model, optimizer)\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_len=5):\n",
    "        \n",
    "    net.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    \n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아래 문장의 정답은 8-4-1-3-5-6-0-2-7\n",
    "## 연예/문화, 정치/경제/사회/생활 등 명확히 구별되기 어려운 범주들이 있음...\n",
    "\n",
    "sentence = \"여러 차례 선거를 치르며 조직적인 지지모임과 온라인 팬덤을 보유한 이 지사에 비해 부족하다는 것이다. 윤석열 캠프에선 오차범위를 다투는 여론조사 지지율과는 별개로, ‘조직’에 있어선 아직도 채워야 할 부분이 많다는 이야기가 나온다. 윤석열 캠프 관계자는 “사람만 많이 모은다고 좋을 게 없다는 지적을 듣기도 하지만, 인구 1300만명의 지자체장인 이재명 지사에 비하면 많은 게 아닌 상황”이라고 말했다.\"\n",
    "sentence =\"여자친구가 이별을 통보하고 새 남자친구를 사귀자 지속적으로 찾아가 협박과 폭행을 가한 30대 남성이 실형을 선고 받았다. 창원지법 형사4단독 안좌진 부장판사는 상해, 주거침입, 폭행 등 혐의로 재판에 넘겨진 A(39)씨에게 징역 1년3개월을 선고했다고 10일 밝혔다.A씨는 지난해 4월부터 올해 2월까지 10개월 가량 사귄 B씨(30)가 이별을 통보하자 지난 3월 6일 B씨 집을 찾아가 욕설을 퍼붓고 B씨를 폭행한 혐의를 받고 있다.\"\n",
    "sentence = \"동탄신도시의 성공은 명실상부한 한국 1위의 기업 삼성전자를 빼놓고는 설명할 수 없다. 삼성전자는 수출의 20%를 담당하는 한국 경제의 심장이다. 삼성전자의 연구소와 공장은 세계 최고 수준의 연구인력과 협력업체를 끌어당기는 블랙홀이다.동탄신도시 인근에 삼성전자 기흥캠퍼스가 있고 화성캠퍼스가 신도시에 자리 잡고 있다. 삼성 화성캠퍼스에서는 메모리와 파운드리 반도체의 설계 및 생산이 이뤄지고 있다.\"\n",
    "sentence = \"샤워나 목욕 중에는 물, 샤워타올, 수건 등 균이 닿을 여지가 많다. 샤워를 하는 화장실에는 보통 변기도 함께 있어 배변 활동으로 나온 균이 공기 중을 돌아다니고 있다. 습기가 높아 곰팡이가 생기기도 좋은 환경이다. 화장실에 걸린 샤워타올과 수건이 제대로 건조되지 않은 채 화장실에 내내 있었다면 균이 있을 가능성이 크다. 이 균이 예방 접종 하면서 생긴 손상 부위에 닿으면 드물지만 침입해 감염증을 유발할 수 있다.\"\n",
    "sentence = \"식전주의 시간이다. 밥을 먹기 전에 마시는 술. 안주와 함께 먹지 않는 술. 술만으로 온전한 술. 이게 식전주다. 3시와 5시 사이는 식전주의 시간이기도 한 것이다. 이 시간에 마시는 식전주를 나는 꽤나 좋아한다. 술은 다 각각의 매력이 있고, 슬플 때도 기쁠 때도 지루할 때도 피곤할 때도 좋지만, 식전주의 시간에 마시는 식전주도 좋다. 주로 맥주이지만 가끔은 아페리티프(Aperitif·식전주)를 마신다.\"\n",
    "sentence = \"시리아전을 마친 뒤 9일 이란으로 출국한 한국 대표팀은 한국 시간 기준 10일 오전 1시경 테헤란 공항에 도착해 숙소인 파르시안 아자디 호텔로 이동했다. 이후 코로나19 PCR 검사를 진행했고, 결과가 나올 때까지 각자 방에서 격리한 채 대기할 예정이다. 한국은 역대 이란 원정에서 한차례도 승리하지 못한 채 2무 5패를 기록 중이다.  선수들이 좋은 컨디션을 유지할 수 있도록 전세기를 마련해 이란으로 향했다.\"\n",
    "sentence = \"애플의 아이폰13 시리즈가 지난 8일 국내 판매를 시작했다. 애플이 지난달 14일(현지시각) 신제품을 공개한 후 3주 만이다. 애플은 아이폰13의 두뇌에 해당하는 프로세서와 카메라 성능을 크게 개선했다고 밝혔다. 팀 쿡 애플 최고경영자(CEO)는 “역사상 최고의 아이폰이다”라고 했다. 하지만 전작인 아이폰12와 비교해 큰 차이를 느낄 수 없다는 부정적인 평가도 많다.\"\n",
    "sentence = \"극단 마실은 문화체육관광부와 지역문화진흥원 지원으로 '심청전-할머니의 비밀레시피' 온라인 만남 행사를 진행했다고 10일 밝혔다. 행사는 할머니만의 레시피로 함께 음식을 만들며 할머니의 이야기를 공유하고, 할머니를 주인공으로 한 짤막한 연극을 펼치는 순서로 진행됐다. 극단은 지역 내 관음사 연기 설화가 심청전과 연관 있는 점을 토대로 심청의 일생과 닮은 곡성 할머니들의 이야기를 2018년도부터 수집해 연극을 만들었다.\"\n",
    "sentence = \"‘놀면 뭐하니?+’에서는 유재석, 정준하, 하하, 신봉선, 미주의 깜짝 ‘꼬치꼬치 기자간담회’와 MBC 보도국 열혈 신입기자로 변신한 ‘뉴스데스크’ 특집이 시작됐다. ‘꼬치꼬치 기자간담회’에서는 정준하가 ‘스포츠 꼬치꼬치’ 기자로 변신, 시청자의 궁금증을 풀어주는 마성의 돌직구 질문을 던졌고, ‘놀면 뭐하니?+’ 멤버들은 솔직한 마음이 담긴 답변으로 큰 웃음과 훈훈함을 동시에 선사했다.\"\n",
    "predict_news(model, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a9e51293b08313c3399046f95d82391d02115e12f4c185f3e9370f950ea95b8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
