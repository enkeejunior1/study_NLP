{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Assignment4_[DS]_물리교육 박용현, 교육 성지훈_v4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWGfWgUjy7dB"
      },
      "source": [
        "# Final Project - Korean to English Translation\n",
        "\n",
        "- Sequence to Sequence 모델의 대표적인 한국어-영어 번역을 Encoder-decoder, Attention, Convolution, 그리고 Transformers 기반으로 구현\n",
        "- 수업시간에 살펴본 Pytorch Seq to Seq 모델 (https://github.com/bentrevett/pytorch-seq2seq)을 참조로 하여 한국어와 영어 형태소분석되고 의존관계로 되어 있는 파일을 프로세싱하여 두 언어의 parallel 데이터 쌍으로 만들고 이를 학습하여 모델별로 Perplexity가 어떻게 달라지는지 살펴 보고, 가장 성능이 좋은 모델을 근간으로 해서 Inference로 한국어 문장을 입력하면 대응되는 영어 번역이 출력될 수 있도록 구현\n",
        "- 반드시 다음 세 모델에 대해서 PPL와 BLEU score가  다 체크되어야 함. (Packed) Encoder-Decoder, Convolutional Seq to Seq, Transformers ...\n",
        "- 세 모델 중에 학습이 제대로 이루어지지 않는 경우, PPL이나 BLEU가 문제가 있는 경우 이를 Fix하려고 시도해 보라.\n",
        "- Inference시에 unk인 단어를 로마자화해서 번역에 나타날 수 있도록 시도해 볼 것(참고할 수 있는 사이트 중 하나 https://github.com/osori/korean-romanizer)\n",
        "\n",
        "- 개인적으로 하거나 최대 두명까지 그룹 허용. \n",
        "- 이 노트북 화일에 이름을 변경하여 작업하고 제출. 제출시 화일명을 Assignment4_[DS또는 CL]_학과_이름.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0ptS_N2y7dE"
      },
      "source": [
        "## Data 1\n",
        "- 첨부된 ko-en-en.parse.syn은 330,974 한국어 문장에 대응되는 영어문장이 품사와 구문분석이 되어 있는 파일이고 ko-en-ko.parse.syn은 이에 대응되는 한국어 문장이 형태소와 구문분석이 되어 있는 파일이다.\n",
        "\n",
        "(ROOT (S (NP (NNP Flight) (NNP 007)) (VP (MD will) (VP (VB stay) (PP (IN on) (NP (NP (DT the) (NN ground)) (PP (IN for) (NP (CD one) (NN hour))))))) (. .)))\n",
        "\n",
        "\n",
        "<id 1>\n",
        "<sent 1>\n",
        "1       2       NP      777/SN\n",
        "2       6       NP_SBJ  항공편/NNG|은/JX\n",
        "3       4       NP      1/SN|시간/NNG\n",
        "4       6       NP_AJT  동안/NNG\n",
        "5       6       NP_AJT  지상/NNG|에/JKB\n",
        "6       7       VP      머물/VV|게/EC\n",
        "7       0       VP      되/VV|ㅂ니다/EF|./SF\n",
        "</sent>\n",
        "</id>\n",
        "\n",
        "    - 이 두 파일을 프로세싱하여 한-영 병렬 데이터로 만들고 이를 학습 및 테스트 데이터로 사용한다.\n",
        "    - Hint: 구조화된 데이터를 프로세싱하기 위해서는 nltk의 모듈을 사용할 수 있다.\n",
        "\n",
        "    - 한국어 형태소 분석된 단위를 어절별로 결합할 수 있고, 분석된 채로 그대로 사용할 수도 있다.\n",
        "    - 두 언어의 어순을 비슷하게 데이터를 만들어 학습할 수도 있고, 번역의 성능을 높이기 위해 다양한 형태로 재구조화 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdS8BqV9y7dF"
      },
      "source": [
        "## Data 2\n",
        "[Korean Parallel Corpora](https://github.com/jungyeul/korean-parallel-corpora)에는 Korean-English-jhe, Korean-English-news-v1의 병렬 데이터가 있다. \n",
        "- 이 데이터를 다운 받아 Data1의 자료와 합쳐서 사용할 수 있다\n",
        "- 이 경우 형태소 분석이 된 경우와 그렇지 않은 자료가 있으니, Data1의 자료와 합칠 때 형태소 분석을 하거나 아니면 어절 단위로 결합하여 할 수도 있다.\n",
        "- 전체적인 일관성 및 inference를 위해서 형태소 분석된 것이 더 좋을 수 있는데, 이 경우 형태소 분석되지 않는 데이터는 새로 형태소 분석을 할 필요. 단 형태소 분석 단위가 일치하는지 알아볼 필요. 형태소 분석 단위가 완전히 일치하지 않는다면 가급적 분석단위 일치도가 높은 형태소 분석기를 선택할 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TV2IZoiy7dF"
      },
      "source": [
        "## 구현,실험 전체적인 설명 및 분석 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwGnpG6vy7dF"
      },
      "source": [
        "## Your Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZoBtH7ay7dG",
        "outputId": "205348b3-60d5-41cf-e4bf-1884a38c7c4a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchtext\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "import json # save parsed list\n",
        "import gensim #!# I used gensim==3.8.1 instead of latest version, since it has some error\n",
        "from nltk import Tree\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# for drawing\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sys import platform\n",
        "if 'linux' == platform:\n",
        "  print('Jeehun Operating code')\n",
        "  from google.colab import drive ; drive.mount('/content/drive') # Colab setting\n",
        "  !pip install einops # Colab setting\n",
        "\n",
        "  # matplotlib\n",
        "  !sudo apt-get install -y fonts-nanum\n",
        "  !sudo fc-cache -fv\n",
        "  !rm ~/.cache/matplotlib -rf\n",
        "\n",
        "  os.chdir('/content/drive/MyDrive/[NLP2021] Ass4')\n",
        "\n",
        "\n",
        "# fm._rebuild() # font reset\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "from einops import rearrange, reduce"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jeehun Operating code\n",
            "Mounted at /content/drive\n",
            "Collecting einops\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 0s (44.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa5qC322qa-K",
        "outputId": "86788318-baa5-4640-c47c-7de132395d83"
      },
      "source": [
        "sys_font=fm.findSystemFonts()\n",
        "print(f\"sys_font number: {len(sys_font)}\")\n",
        "\n",
        "nanum_font = [f for f in sys_font if 'Nanum' in f]\n",
        "print(f\"nanum_font number: {len(nanum_font)}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys_font number: 27\n",
            "nanum_font number: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GtdXgeDqeFM",
        "outputId": "12f6aa5a-3751-4ec0-8d3a-bf23b05ba11e"
      },
      "source": [
        "nanum_font"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumSquareRoundR.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumMyeongjoBold.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumSquareRoundB.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumSquareB.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumSquareR.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumBarunGothicBold.ttf',\n",
              " '/usr/share/fonts/truetype/nanum/NanumGothic.ttf']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5tU0ND2qpQy",
        "outputId": "7ec17c3f-1143-4cf8-bd17-c07f40318411"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져오자\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rc('font', family=font_name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NanumBarunGothic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eUQGHPtyOvG",
        "outputId": "f7b38bfa-f432-49d8-9945-abd038d731bc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 21 13:40:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfQjR6qdy7dH"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl3bOkEFy7dH",
        "outputId": "cfadd426-476b-4c80-9e1a-e7d89fd0ac06"
      },
      "source": [
        "with open('ko-en.ko.parse','r') as f:\n",
        "    ko = list(f)\n",
        "\n",
        "## split 으로 구분할 수 있는 형태로 전처리\n",
        "# 문장 단위로 분리하기\n",
        "# 문장 내부에서 token 추출하기\n",
        "\n",
        "def extract_sentence(token_list):\n",
        "    '''extract <sent #> sth </sent>'''\n",
        "    sentence_list = []\n",
        "    sentence = ''\n",
        "    in_sentence = False\n",
        "\n",
        "    for tok in token_list:\n",
        "        if '<id' in tok:\n",
        "            in_sentence = True\n",
        "\n",
        "        if in_sentence:\n",
        "            sentence += tok\n",
        "\n",
        "        if '</id>' in tok:\n",
        "            sentence_list.append(sentence)\n",
        "            in_sentence = False\n",
        "            sentence = ''\n",
        "            \n",
        "    return sentence_list\n",
        "\n",
        "def extract_token(segment_with_morpheme) -> list:\n",
        "    '''split token/morpheme|...|token/morpheme'''\n",
        "    '''since we tokenize the data before import on torchtext, convert every string object to lowercase'''\n",
        "    token_list = []\n",
        "    if '|' in segment_with_morpheme: # multiple token in a sement\n",
        "        for token in segment_with_morpheme.split(sep = '|'):\n",
        "            token_list.append(str.lower(token.split(sep = '/')[0]))\n",
        "        \n",
        "    else: # multiple token in a sement\n",
        "        token_list.append(str.lower(segment_with_morpheme.split(sep = '/')[0]))\n",
        "        \n",
        "    return token_list\n",
        "\n",
        "def preprocess(ko):\n",
        "    processed_sentence_list = []\n",
        "    sentence_list = extract_sentence(ko)\n",
        "    \n",
        "    for sentence in tqdm(sentence_list):\n",
        "        processed_token_list = []\n",
        "        for segment in sentence.split(sep = '\\n'):\n",
        "            if '\\t' in segment:\n",
        "                token_with_morpheme = segment.split(sep = '\\t')[-1]\n",
        "                processed_token_list += extract_token(token_with_morpheme)\n",
        "                \n",
        "        processed_token_list.insert(0, '<sos>')\n",
        "        processed_token_list.append('<eos>')\n",
        "        processed_sentence_list.append(processed_token_list)\n",
        "\n",
        "    return processed_sentence_list\n",
        "\n",
        "processed_ko = preprocess(ko)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 330974/330974 [00:04<00:00, 66329.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmy5vssby7dI",
        "outputId": "5bdfb403-3c19-4a74-d60c-7123bfd6ee17"
      },
      "source": [
        "# English data\n",
        "with open('ko-en.en.parse.syn') as f:\n",
        "    en = f.readlines()\n",
        "\n",
        "processed_en = []\n",
        "for idx, _ in tqdm(enumerate(en)):\n",
        "    t = Tree.fromstring(en[idx])\n",
        "    processed_token_list = [str.lower(token) for token in t.leaves()]\n",
        "    \n",
        "    processed_token_list.insert(0, '<sos>')\n",
        "    processed_token_list.append('<eos>')\n",
        "    \n",
        "    processed_en.append(processed_token_list)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "330974it [00:25, 13189.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAaAqw9_y7dI"
      },
      "source": [
        "## torchtext 에 전달하기\n",
        "# save parsed dataset as a json file\n",
        "split_idx = len(processed_ko) // 10\n",
        "\n",
        "ko_en_json_train = [{'ko' : ko, 'en' : en} for ko, en in zip(processed_ko[:split_idx*8], processed_en[:split_idx*8])] #!# change it after practice\n",
        "ko_en_json_valid = [{'ko' : ko, 'en' : en} for ko, en in zip(processed_ko[split_idx*8:split_idx*9], processed_en[split_idx*8:split_idx*9])] #!# change it after practice\n",
        "ko_en_json_test  = [{'ko' : ko, 'en' : en} for ko, en in zip(processed_ko[split_idx*9:], processed_en[split_idx*9:])] #!# change it after practice\n",
        "\n",
        "ko_en_json_small = [{'ko' : ko, 'en' : en} for ko, en in zip(processed_ko[:256*8], processed_en[:256*8])] #!# for debug"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSPJ-KPnGKka"
      },
      "source": [
        "with open(\"ko_en_parsed_train.json\" , encoding= \"utf-8\", mode=\"w\") as file: \n",
        "    for i in ko_en_json_train: file.write(json.dumps(i) + \"\\n\")\n",
        "        \n",
        "with open(\"ko_en_parsed_valid.json\" , encoding= \"utf-8\", mode=\"w\") as file: \n",
        "    for i in ko_en_json_valid: file.write(json.dumps(i) + \"\\n\")\n",
        "        \n",
        "with open(\"ko_en_parsed_test.json\" , encoding= \"utf-8\", mode=\"w\") as file: \n",
        "    for i in ko_en_json_test: file.write(json.dumps(i) + \"\\n\")\n",
        "\n",
        "  \n",
        "with open(\"ko_en_parsed_small.json\" , encoding= \"utf-8\", mode=\"w\") as file: \n",
        "    for i in ko_en_json_test: file.write(json.dumps(i) + \"\\n\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E377ERXcy7dJ",
        "outputId": "acdeb8c3-060e-4414-e3c0-d3a9f8b85a2a"
      },
      "source": [
        "## pack padded seq2seq\n",
        "# torchtext iterator 만들어주기\n",
        "KOREAN = data.Field( \n",
        "    init_token = '<sos>', \n",
        "    eos_token = '<eos>', \n",
        "    include_lengths = True\n",
        ")\n",
        "\n",
        "ENGLISH = data.Field( \n",
        "    init_token = '<sos>', \n",
        "    eos_token = '<eos>'\n",
        ")\n",
        "\n",
        "fields  = {'ko' : ('ko', KOREAN), 'en' : ('en', ENGLISH)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                            path  = os.getcwd(), #!#\n",
        "                            # train = \"ko_en_parsed_small.json\", #!# 'ko_en_parsed_train.json'\n",
        "                            # test  = \"ko_en_parsed_small.json\", #!# 'ko_en_parsed_test.json'\n",
        "\n",
        "                            train = \"ko_en_parsed_train.json\", \n",
        "                            validation = \"ko_en_parsed_valid.json\", \n",
        "                            test  = \"ko_en_parsed_test.json\",\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")\n",
        "\n",
        "print(vars(train_data.examples[63])['en'])\n",
        "print(vars(train_data.examples[63])['ko'])\n",
        "\n",
        "BATCH_SIZE = 128 #!# hyper parameter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "     (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.ko),\n",
        "     device = device)\n",
        "\n",
        "KOREAN.build_vocab(train_data, max_size=10000, min_freq=2) # Word2Vec 모델을 임베딩 벡터값으로 초기화\n",
        "\n",
        "ENGLISH.build_vocab(train_data, max_size=10000, min_freq=2) # Word2Vec 모델을 임베딩 벡터값으로 초기화"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<sos>', '10', 'minutes', '.', 'never', 'mind', '.', '<eos>']\n",
            "['<sos>', '10', '분', '이', 'ㅂ니다', '.', '신경', '쓰', '지', '말', '시', '어요', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGdrtJyoy7dJ",
        "outputId": "c394af70-6e41-451e-a55f-4f3041bc849e"
      },
      "source": [
        "## Conv. seq2seq, Transfomer seq2seq\n",
        "# torchtext iterator 만들어주기\n",
        "CNN_KOREAN = data.Field( \n",
        "#     sequential = False, #!#\n",
        "    init_token = '<sos>', \n",
        "    eos_token = '<eos>', \n",
        "    batch_first = True,\n",
        "    include_lengths = False #!#\n",
        ")\n",
        "\n",
        "CNN_ENGLISH = data.Field( \n",
        "    init_token = '<sos>', \n",
        "    eos_token = '<eos>', \n",
        "    batch_first = True\n",
        ")\n",
        "\n",
        "CNN_fields  = {'ko' : ('ko', CNN_KOREAN), 'en' : ('en', CNN_ENGLISH)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                            path  = os.getcwd(), #!#\n",
        "                            # train = \"ko_en_parsed_small.json\", #!# 'ko_en_parsed_train.json'\n",
        "                            # test  = \"ko_en_parsed_small.json\", #!# 'ko_en_parsed_test.json'\n",
        "\n",
        "                            train = \"ko_en_parsed_train.json\", #!# 'ko_en_parsed_train.json'\n",
        "                            validation = \"ko_en_parsed_valid.json\",\n",
        "                            test  = \"ko_en_parsed_test.json\", #!# 'ko_en_parsed_test.json'\n",
        "                            format = 'json',\n",
        "                            fields = CNN_fields\n",
        ")\n",
        "\n",
        "print(vars(train_data.examples[63])['en'])\n",
        "print(vars(test_data.examples[63])['ko'])\n",
        "\n",
        "BATCH_SIZE = 128 #!# hyper parameter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "CNN_train_iterator,CNN_valid_iterator, CNN_test_iterator = data.BucketIterator.splits(\n",
        "     (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.ko),\n",
        "     device = device)\n",
        "\n",
        "CNN_KOREAN.build_vocab(train_data, max_size=10000, min_freq=2) # Word2Vec 모델을 임베딩 벡터값으로 초기화\n",
        "\n",
        "CNN_ENGLISH.build_vocab(train_data, max_size=10000, min_freq=2) # Word2Vec 모델을 임베딩 벡터값으로 초기화"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<sos>', '10', 'minutes', '.', 'never', 'mind', '.', '<eos>']\n",
            "['<sos>', '와우', '!', '고맙', '어', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vk3cHhby7dL"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07P32jbYy7dL",
        "outputId": "bc45aa73-a942-45b7-f039-ab3fdd5fda0b"
      },
      "source": [
        "## model building\n",
        "# preparation\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz84KK8Iy7dL"
      },
      "source": [
        "### \\<pack padded\\> seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRl9kB7y7dL"
      },
      "source": [
        "## model 1 : (Packed) Encoder-Decoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        #need to explicitly put lengths on cpu!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                                 \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "  \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention = [batch size, src len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        #mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "            #  and mask\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7NjyQ5R1QD_"
      },
      "source": [
        "### 2. CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BKj7Touy7dN"
      },
      "source": [
        "## model 2 : Convolutional Seq to Seq\n",
        "class Conv_Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 emb_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 kernel_size, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, emb_dim)\n",
        "        \n",
        "        self.emb2hid = nn.Linear(emb_dim, hid_dim)\n",
        "        self.hid2emb = nn.Linear(hid_dim, emb_dim)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_dim, \n",
        "                                              out_channels = 2 * hid_dim, \n",
        "                                              kernel_size = kernel_size, \n",
        "                                              padding = (kernel_size - 1) // 2)\n",
        "                                    for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        #create position tensor\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [0, 1, 2, 3, ..., src len - 1]\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        #embed tokens and positions\n",
        "        tok_embedded = self.tok_embedding(src)\n",
        "        pos_embedded = self.pos_embedding(pos)\n",
        "        \n",
        "        #tok_embedded = pos_embedded = [batch size, src len, emb dim]\n",
        "        \n",
        "        #combine embeddings by elementwise summing\n",
        "        embedded = self.dropout(tok_embedded + pos_embedded)\n",
        "        \n",
        "        #embedded = [batch size, src len, emb dim]\n",
        "        \n",
        "        #pass embedded through linear layer to convert from emb dim to hid dim\n",
        "        conv_input = self.emb2hid(embedded)\n",
        "        \n",
        "        #conv_input = [batch size, src len, hid dim]\n",
        "        \n",
        "        #permute for convolutional layer\n",
        "        conv_input = conv_input.permute(0, 2, 1) \n",
        "        \n",
        "        #conv_input = [batch size, hid dim, src len]\n",
        "        \n",
        "        #begin convolutional blocks...\n",
        "        \n",
        "        for i, conv in enumerate(self.convs):\n",
        "        \n",
        "            #pass through convolutional layer\n",
        "            conved = conv(self.dropout(conv_input))\n",
        "\n",
        "            #conved = [batch size, 2 * hid dim, src len]\n",
        "\n",
        "            #pass through GLU activation function\n",
        "            conved = F.glu(conved, dim = 1)\n",
        "\n",
        "            #conved = [batch size, hid dim, src len]\n",
        "            \n",
        "            #apply residual connection\n",
        "            conved = (conved + conv_input) * self.scale\n",
        "\n",
        "            #conved = [batch size, hid dim, src len]\n",
        "            \n",
        "            #set conv_input to conved for next loop iteration\n",
        "            conv_input = conved\n",
        "        \n",
        "        #...end convolutional blocks\n",
        "        \n",
        "        #permute and convert back to emb dim\n",
        "        conved = self.hid2emb(conved.permute(0, 2, 1))\n",
        "        \n",
        "        #conved = [batch size, src len, emb dim]\n",
        "        \n",
        "        #elementwise sum output (conved) and input (embedded) to be used for attention\n",
        "        combined = (conved + embedded) * self.scale\n",
        "        \n",
        "        #combined = [batch size, src len, emb dim]\n",
        "        \n",
        "        return conved, combined\n",
        "\n",
        "class Conv_Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 emb_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 kernel_size, \n",
        "                 dropout, \n",
        "                 trg_pad_idx, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, emb_dim)\n",
        "        \n",
        "        self.emb2hid = nn.Linear(emb_dim, hid_dim)\n",
        "        self.hid2emb = nn.Linear(hid_dim, emb_dim)\n",
        "        \n",
        "        self.attn_hid2emb = nn.Linear(hid_dim, emb_dim)\n",
        "        self.attn_emb2hid = nn.Linear(emb_dim, hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "        \n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_dim, \n",
        "                                              out_channels = 2 * hid_dim, \n",
        "                                              kernel_size = kernel_size)\n",
        "                                    for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "      \n",
        "    def calculate_attention(self, embedded, conved, encoder_conved, encoder_combined):\n",
        "        \n",
        "        #embedded = [batch size, trg len, emb dim]\n",
        "        #conved = [batch size, hid dim, trg len]\n",
        "        #encoder_conved = encoder_combined = [batch size, src len, emb dim]\n",
        "        \n",
        "        #permute and convert back to emb dim\n",
        "        conved_emb = self.attn_hid2emb(conved.permute(0, 2, 1))\n",
        "        \n",
        "        #conved_emb = [batch size, trg len, emb dim]\n",
        "        \n",
        "        combined = (conved_emb + embedded) * self.scale\n",
        "        \n",
        "        #combined = [batch size, trg len, emb dim]\n",
        "                \n",
        "        energy = torch.matmul(combined, encoder_conved.permute(0, 2, 1))\n",
        "        \n",
        "        #energy = [batch size, trg len, src len]\n",
        "        \n",
        "        attention = F.softmax(energy, dim=2)\n",
        "        \n",
        "        #attention = [batch size, trg len, src len]\n",
        "            \n",
        "        attended_encoding = torch.matmul(attention, encoder_combined)\n",
        "        \n",
        "        #attended_encoding = [batch size, trg len, emd dim]\n",
        "        \n",
        "        #convert from emb dim -> hid dim\n",
        "        attended_encoding = self.attn_emb2hid(attended_encoding)\n",
        "        \n",
        "        #attended_encoding = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #apply residual connection\n",
        "        attended_combined = (conved + attended_encoding.permute(0, 2, 1)) * self.scale\n",
        "        \n",
        "        #attended_combined = [batch size, hid dim, trg len]\n",
        "        \n",
        "        return attention, attended_combined\n",
        "        \n",
        "    def forward(self, trg, encoder_conved, encoder_combined):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #encoder_conved = encoder_combined = [batch size, src len, emb dim]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "            \n",
        "        #create position tensor\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, trg len]\n",
        "        \n",
        "        #embed tokens and positions\n",
        "        tok_embedded = self.tok_embedding(trg)\n",
        "        pos_embedded = self.pos_embedding(pos)\n",
        "        \n",
        "        #tok_embedded = [batch size, trg len, emb dim]\n",
        "        #pos_embedded = [batch size, trg len, emb dim]\n",
        "        \n",
        "        #combine embeddings by elementwise summing\n",
        "        embedded = self.dropout(tok_embedded + pos_embedded)\n",
        "        \n",
        "        #embedded = [batch size, trg len, emb dim]\n",
        "        \n",
        "        #pass embedded through linear layer to go through emb dim -> hid dim\n",
        "        conv_input = self.emb2hid(embedded)\n",
        "        \n",
        "        #conv_input = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #permute for convolutional layer\n",
        "        conv_input = conv_input.permute(0, 2, 1) \n",
        "        \n",
        "        #conv_input = [batch size, hid dim, trg len]\n",
        "        \n",
        "        batch_size = conv_input.shape[0]\n",
        "        hid_dim = conv_input.shape[1]\n",
        "        \n",
        "        for i, conv in enumerate(self.convs):\n",
        "        \n",
        "            #apply dropout\n",
        "            conv_input = self.dropout(conv_input)\n",
        "        \n",
        "            #need to pad so decoder can't \"cheat\"\n",
        "            padding = torch.zeros(batch_size, \n",
        "                                  hid_dim, \n",
        "                                  self.kernel_size - 1).fill_(self.trg_pad_idx).to(self.device)\n",
        "                \n",
        "            padded_conv_input = torch.cat((padding, conv_input), dim = 2)\n",
        "        \n",
        "            #padded_conv_input = [batch size, hid dim, trg len + kernel size - 1]\n",
        "        \n",
        "            #pass through convolutional layer\n",
        "            conved = conv(padded_conv_input)\n",
        "\n",
        "            #conved = [batch size, 2 * hid dim, trg len]\n",
        "            \n",
        "            #pass through GLU activation function\n",
        "            conved = F.glu(conved, dim = 1)\n",
        "\n",
        "            #conved = [batch size, hid dim, trg len]\n",
        "            \n",
        "            #calculate attention\n",
        "            attention, conved = self.calculate_attention(embedded, \n",
        "                                                         conved, \n",
        "                                                         encoder_conved, \n",
        "                                                         encoder_combined)\n",
        "            \n",
        "            #attention = [batch size, trg len, src len]\n",
        "            \n",
        "            #apply residual connection\n",
        "            conved = (conved + conv_input) * self.scale\n",
        "            \n",
        "            #conved = [batch size, hid dim, trg len]\n",
        "            \n",
        "            #set conv_input to conved for next loop iteration\n",
        "            conv_input = conved\n",
        "            \n",
        "        conved = self.hid2emb(conved.permute(0, 2, 1))\n",
        "         \n",
        "        #conved = [batch size, trg len, emb dim]\n",
        "            \n",
        "        output = self.fc_out(self.dropout(conved))\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention\n",
        "\n",
        "class Conv_Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len - 1] (<eos> token sliced off the end)\n",
        "           \n",
        "        #calculate z^u (encoder_conved) and (z^u + e) (encoder_combined)\n",
        "        #encoder_conved is output from final encoder conv. block\n",
        "        #encoder_combined is encoder_conved plus (elementwise) src embedding plus \n",
        "        #  positional embeddings \n",
        "        encoder_conved, encoder_combined = self.encoder(src)\n",
        "            \n",
        "        #encoder_conved = [batch size, src len, emb dim]\n",
        "        #encoder_combined = [batch size, src len, emb dim]\n",
        "        \n",
        "        #calculate predictions of next words\n",
        "        #output is a batch of predictions for each word in the trg sentence\n",
        "        #attention a batch of attention scores across the src sentence for \n",
        "        #  each word in the trg sentence\n",
        "        output, attention = self.decoder(trg, encoder_conved, encoder_combined)\n",
        "        \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #attention = [batch size, trg len - 1, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StdxXlXh1MwX"
      },
      "source": [
        "### 3. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WvHVm16y7dN"
      },
      "source": [
        "## model 3 : Transformers\n",
        "class Transformer_Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention\n",
        "\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x\n",
        "class Transformer_Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention\n",
        "    \n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention\n",
        "    \n",
        "class Transformer_Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63mGQoly7dO"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p4Bmn8Yy7dO"
      },
      "source": [
        "## training\n",
        "# model 1 : pack padded seq2seq\n",
        "INPUT_DIM   = len(KOREAN.vocab)  #!# same for-pretrained vocab?\n",
        "OUTPUT_DIM  = len(ENGLISH.vocab) #!# same for-pretrained vocab?\n",
        "ENC_EMB_DIM = 256 #!# 300\n",
        "DEC_EMB_DIM = 256 #!# 300\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "KO_PAD_IDX = KOREAN.vocab.stoi[KOREAN.pad_token]\n",
        "EN_PAD_IDX = ENGLISH.vocab.stoi[ENGLISH.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc  = Encoder(INPUT_DIM,  ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec  = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "Seq2Seq_model = Seq2Seq(enc, dec, KO_PAD_IDX, device).to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "Seq2Seq_model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(Seq2Seq_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = EN_PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        ko, ko_len = batch.ko\n",
        "        en = batch.en\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(ko, ko_len, en)\n",
        "        \n",
        "        #en = [en len, batch size]\n",
        "        #output = [en len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        en = en[1:].view(-1)\n",
        "        \n",
        "        #en = [(en len - 1) * batch size]\n",
        "        #output = [(en len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, en)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            ko, ko_len = batch.ko\n",
        "            en = batch.en\n",
        "\n",
        "            output = model(ko, ko_len, en, 0) #turn off teacher forcing\n",
        "            \n",
        "            #en = [en len, batch size]\n",
        "            #output = [en len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            en = en[1:].view(-1)\n",
        "\n",
        "            #en = [(en len - 1) * batch size]\n",
        "            #output = [(en len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, en)\n",
        "\n",
        "            epoch_loss += loss.item() # '+= loss' 에 비해서 메모리를 아껴주는 방법\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZNxnocqlkDc"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhG59NqTzIyc"
      },
      "source": [
        "# https://discuss.pytorch.org/t/how-can-we-release-gpu-memory-cache/14530/29\n",
        "# https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html # cuda.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9q5yx4Zy7dO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa50236-7849-479f-b192-b540410b73d8"
      },
      "source": [
        "# model 1 : pack padded seq2seq\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    torch.cuda.empty_cache() # to release cache memory \n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(Seq2Seq_model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(Seq2Seq_model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(Seq2Seq_model.state_dict(), 'Seq2Seq_model.pt')\n",
        "    # else: # for memory\n",
        "\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 6m 9s\n",
            "\tTrain Loss: 2.840 | Train PPL:  17.117\n",
            "\t Val. Loss: 3.104 |  Val. PPL:  22.296\n",
            "Epoch: 02 | Time: 6m 10s\n",
            "\tTrain Loss: 1.814 | Train PPL:   6.133\n",
            "\t Val. Loss: 2.700 |  Val. PPL:  14.881\n",
            "Epoch: 03 | Time: 6m 10s\n",
            "\tTrain Loss: 1.536 | Train PPL:   4.648\n",
            "\t Val. Loss: 2.515 |  Val. PPL:  12.368\n",
            "Epoch: 04 | Time: 6m 9s\n",
            "\tTrain Loss: 1.384 | Train PPL:   3.992\n",
            "\t Val. Loss: 2.394 |  Val. PPL:  10.953\n",
            "Epoch: 05 | Time: 6m 9s\n",
            "\tTrain Loss: 1.289 | Train PPL:   3.629\n",
            "\t Val. Loss: 2.302 |  Val. PPL:   9.995\n",
            "Epoch: 06 | Time: 6m 10s\n",
            "\tTrain Loss: 1.225 | Train PPL:   3.404\n",
            "\t Val. Loss: 2.241 |  Val. PPL:   9.401\n",
            "Epoch: 07 | Time: 6m 9s\n",
            "\tTrain Loss: 1.173 | Train PPL:   3.231\n",
            "\t Val. Loss: 2.146 |  Val. PPL:   8.548\n",
            "Epoch: 08 | Time: 6m 9s\n",
            "\tTrain Loss: 1.143 | Train PPL:   3.136\n",
            "\t Val. Loss: 2.083 |  Val. PPL:   8.030\n",
            "Epoch: 09 | Time: 6m 9s\n",
            "\tTrain Loss: 1.108 | Train PPL:   3.029\n",
            "\t Val. Loss: 2.039 |  Val. PPL:   7.681\n",
            "Epoch: 10 | Time: 6m 9s\n",
            "\tTrain Loss: 1.071 | Train PPL:   2.920\n",
            "\t Val. Loss: 2.020 |  Val. PPL:   7.539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB92NmnMy7dO"
      },
      "source": [
        "# model 2 : Conv. seq2seq\n",
        "#!# batch-first 에 주의할 것\n",
        "INPUT_DIM  = len(CNN_KOREAN.vocab)\n",
        "OUTPUT_DIM = len(CNN_ENGLISH.vocab)\n",
        "EMB_DIM = 256 #!# 300\n",
        "HID_DIM = 512 # each conv. layer has 2 * hid_dim filters\n",
        "ENC_LAYERS = 10 # number of conv. blocks in encoder\n",
        "DEC_LAYERS = 10 # number of conv. blocks in decoder\n",
        "ENC_KERNEL_SIZE = 3 # must be odd!\n",
        "DEC_KERNEL_SIZE = 3 # can be even or odd\n",
        "ENC_DROPOUT = 0.25\n",
        "DEC_DROPOUT = 0.25\n",
        "EN_PAD_IDX = CNN_ENGLISH.vocab.stoi[CNN_ENGLISH.pad_token]\n",
        "    \n",
        "enc = Conv_Encoder(INPUT_DIM,  EMB_DIM, HID_DIM, ENC_LAYERS, ENC_KERNEL_SIZE, ENC_DROPOUT, device)\n",
        "dec = Conv_Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, DEC_LAYERS, DEC_KERNEL_SIZE, DEC_DROPOUT, EN_PAD_IDX, device)\n",
        "\n",
        "CNN_model = Conv_Seq2Seq(enc, dec).to(device)\n",
        "\n",
        "optimizer = optim.Adam(CNN_model.parameters())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = EN_PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        ko = batch.ko\n",
        "        en = batch.en\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(ko, en[:,:-1])\n",
        "        \n",
        "        #output = [batch size, en len - 1, output dim]\n",
        "        #en = [batch size, en len]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        en = en[:,1:].contiguous().view(-1)\n",
        "        \n",
        "        #output = [batch size * en len - 1, output dim]\n",
        "        #en = [batch size * en len - 1]\n",
        "        \n",
        "        loss = criterion(output, en)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            ko = batch.ko\n",
        "            en = batch.en\n",
        "\n",
        "            output, _ = model(ko, en[:,:-1])\n",
        "        \n",
        "            #output = [batch size, en len - 1, output dim]\n",
        "            #en = [batch size, en len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            en = en[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * en len - 1, output dim]\n",
        "            #en = [batch size * en len - 1]\n",
        "            \n",
        "            loss = criterion(output, en)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLJlBppy7dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783683e8-c24c-4e5f-9b86-9e94cab28dd6"
      },
      "source": [
        "# model 2 : Conv. seq2seq\n",
        "\n",
        "# before training for saving memory\n",
        "# del Seq2Seq_model \n",
        "# \n",
        "N_EPOCHS = 10\n",
        "CLIP = 0.1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(CNN_model, CNN_train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(CNN_model, CNN_valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(CNN_model.state_dict(), 'CNN_model.pt')\n",
        "\n",
        "\n",
        "    if train_loss > 10**4:\n",
        "      print('Model Exploit, training stop: ', train_loss)\n",
        "      break\n",
        "    \n",
        "    else:\n",
        "      print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 4m 7s\n",
            "\tTrain Loss: 2.445 | Train PPL:  11.526\n",
            "\t Val. Loss: 2.073 |  Val. PPL:   7.945\n",
            "Epoch: 02 | Time: 4m 5s\n",
            "\tTrain Loss: 1.725 | Train PPL:   5.614\n",
            "\t Val. Loss: 1.802 |  Val. PPL:   6.062\n",
            "Epoch: 03 | Time: 4m 5s\n",
            "\tTrain Loss: 1.539 | Train PPL:   4.661\n",
            "\t Val. Loss: 1.660 |  Val. PPL:   5.257\n",
            "Epoch: 04 | Time: 4m 5s\n",
            "\tTrain Loss: 1.424 | Train PPL:   4.154\n",
            "\t Val. Loss: 1.544 |  Val. PPL:   4.682\n",
            "Epoch: 05 | Time: 4m 5s\n",
            "\tTrain Loss: 1.330 | Train PPL:   3.780\n",
            "\t Val. Loss: 1.459 |  Val. PPL:   4.301\n",
            "Epoch: 06 | Time: 4m 5s\n",
            "\tTrain Loss: 1.367 | Train PPL:   3.923\n",
            "\t Val. Loss: 1.402 |  Val. PPL:   4.063\n",
            "Epoch: 07 | Time: 4m 5s\n",
            "\tTrain Loss: 1.247 | Train PPL:   3.479\n",
            "\t Val. Loss: 1.343 |  Val. PPL:   3.831\n",
            "Epoch: 08 | Time: 4m 5s\n",
            "\tTrain Loss: 1.311 | Train PPL:   3.709\n",
            "\t Val. Loss: 1.299 |  Val. PPL:   3.664\n",
            "Epoch: 09 | Time: 4m 5s\n",
            "\tTrain Loss: 1.143 | Train PPL:   3.135\n",
            "\t Val. Loss: 1.250 |  Val. PPL:   3.489\n",
            "Model Exploit, training stop:  4496981.261425788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuG6dsxpy7dP"
      },
      "source": [
        "# model 3 : transformer\n",
        "INPUT_DIM = len(CNN_KOREAN.vocab)\n",
        "OUTPUT_DIM = len(CNN_ENGLISH.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Transformer_Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Transformer_Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "KO_PAD_IDX = CNN_KOREAN.vocab.stoi[CNN_KOREAN.pad_token]\n",
        "EN_PAD_IDX = CNN_ENGLISH.vocab.stoi[CNN_ENGLISH.pad_token]\n",
        "\n",
        "transformer_model = Transformer_Seq2Seq(enc, dec, KO_PAD_IDX, EN_PAD_IDX, device).to(device)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "transformer_model.apply(initialize_weights)\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer_model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = EN_PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        ko = batch.ko\n",
        "        en = batch.en\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(ko, en[:,:-1])\n",
        "                \n",
        "        #output = [batch size, en len - 1, output dim]\n",
        "        #en = [batch size, en len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        en = en[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * en len - 1, output dim]\n",
        "        #en = [batch size * en len - 1]\n",
        "            \n",
        "        loss = criterion(output, en)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            ko = batch.ko\n",
        "            en = batch.en\n",
        "\n",
        "            output, _ = model(ko, en[:,:-1])\n",
        "            \n",
        "            #output = [batch size, en len - 1, output dim]\n",
        "            #en = [batch size, en len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            en = en[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * en len - 1, output dim]\n",
        "            #en = [batch size * en len - 1]\n",
        "            \n",
        "            loss = criterion(output, en)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiR2tpiky7dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a09fd9a-f475-415c-83a9-8f0fe26e2a74"
      },
      "source": [
        "# model 3 : transformer\n",
        "\n",
        "# before training for saving memory\n",
        "# del CNN_model\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(transformer_model, CNN_train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(transformer_model, CNN_valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(transformer_model.state_dict(), 'transformer_model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 28s\n",
            "\tTrain Loss: 1.159 | Train PPL:   3.185\n",
            "\t Val. Loss: 1.274 |  Val. PPL:   3.575\n",
            "Epoch: 02 | Time: 1m 28s\n",
            "\tTrain Loss: 0.959 | Train PPL:   2.609\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.999\n",
            "Epoch: 03 | Time: 1m 27s\n",
            "\tTrain Loss: 0.850 | Train PPL:   2.339\n",
            "\t Val. Loss: 0.989 |  Val. PPL:   2.689\n",
            "Epoch: 04 | Time: 1m 27s\n",
            "\tTrain Loss: 0.775 | Train PPL:   2.170\n",
            "\t Val. Loss: 0.891 |  Val. PPL:   2.438\n",
            "Epoch: 05 | Time: 1m 27s\n",
            "\tTrain Loss: 0.719 | Train PPL:   2.053\n",
            "\t Val. Loss: 0.829 |  Val. PPL:   2.290\n",
            "Epoch: 06 | Time: 1m 27s\n",
            "\tTrain Loss: 0.675 | Train PPL:   1.964\n",
            "\t Val. Loss: 0.772 |  Val. PPL:   2.163\n",
            "Epoch: 07 | Time: 1m 27s\n",
            "\tTrain Loss: 0.640 | Train PPL:   1.896\n",
            "\t Val. Loss: 0.724 |  Val. PPL:   2.063\n",
            "Epoch: 08 | Time: 1m 27s\n",
            "\tTrain Loss: 0.610 | Train PPL:   1.840\n",
            "\t Val. Loss: 0.687 |  Val. PPL:   1.987\n",
            "Epoch: 09 | Time: 1m 27s\n",
            "\tTrain Loss: 0.585 | Train PPL:   1.794\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Epoch: 10 | Time: 1m 27s\n",
            "\tTrain Loss: 0.562 | Train PPL:   1.755\n",
            "\t Val. Loss: 0.620 |  Val. PPL:   1.859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-asv8uzy7dP"
      },
      "source": [
        "## result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InVqKhFuy7dP"
      },
      "source": [
        "## Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f13LjNejy7dP"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        attentions[i] = attention\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n",
        "\n",
        "def CNN_translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    # if isinstance(sentence, str):\n",
        "    #     nlp = spacy.load('de_core_news_sm')\n",
        "    #     tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    # else:\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "            # output, attention = model.decoder(trg_tensor, enc_src)\n",
        "            # output, attention = model.decoder(enc_src, trg_tensor)\n",
        "            # output, attention = model.decoder()\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention\n",
        "\n",
        "def transformer_translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    # if isinstance(sentence, str):\n",
        "    #     nlp = spacy.load('de_core_news_sm')\n",
        "    #     tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    # else:\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention\n",
        "\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, translate_sentence, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['ko']\n",
        "        trg = vars(datum)['en']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHrwNAWJy7dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24802fb-fbd5-41f1-e392-d9d19f5b8a28"
      },
      "source": [
        "## pack padded\n",
        "seq_bleu_score = calculate_bleu(test_data, KOREAN, ENGLISH, Seq2Seq_model, device, translate_sentence)\n",
        "print(f'BLEU score = {seq_bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score = 33.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrE5Nbey7dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc52554-0fc7-49d4-f638-e19065702ca4"
      },
      "source": [
        "## CNN\n",
        "cnn_bleu_score = calculate_bleu(test_data, CNN_KOREAN, CNN_ENGLISH, CNN_model, device, CNN_translate_sentence, max_len = 50)\n",
        "print(f'BLEU score = {cnn_bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score = 25.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31XUkwD_y7dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8368aa-3fda-4156-eace-6490f4b6e64a"
      },
      "source": [
        "## transformer\n",
        "transformer_bleu_score = calculate_bleu(test_data, CNN_KOREAN, CNN_ENGLISH, transformer_model, device, transformer_translate_sentence, max_len = 50)\n",
        "print(f'BLEU score = {transformer_bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score = 39.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TrSWbbQy7dQ"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQP4gVLonD6q",
        "outputId": "fc521b5d-48c5-4ba7-de83-7eaebdb459f6"
      },
      "source": [
        "MODEL_PATH = os.path.join(os.getcwd(), 'Seq2Seq_model.pt')\n",
        "Seq2Seq_model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AGI6VoJWwcF",
        "outputId": "6bd944b7-0a97-48d9-c72e-679bd17783cd"
      },
      "source": [
        "MODEL_PATH = os.path.join(os.getcwd(), 'CNN_model.pt')\n",
        "CNN_model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xjk5RiT2tzY"
      },
      "source": [
        "# Trnaslation\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    # if isinstance(sentence, str):\n",
        "    #     nlp = spacy.load('de')\n",
        "    #     tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    # else:\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        attentions[i] = attention\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n",
        "\n",
        "\n",
        "# Visualization\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    \n",
        "    x_ticks = [''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>']\n",
        "    y_ticks = [''] + translation\n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JAyPIWYy7dQ"
      },
      "source": [
        "## 형태소 분석을 할 경우\n",
        "\n",
        "sen_list = [\n",
        "'모든 액체 , 젤 , 에어로졸 등 은 1 커트 짜리 여닫이 투명 봉지 하나 에 넣 어야 하 ㅂ니다 .',\n",
        "'미안 하 지만 , 뒷쪽 아이 들 의 떠들 는 소리 가 커 어서 , 광화문 으로 가 아고 싶 은데 표 를 바꾸 어 주 시 겠 어요 ?',\n",
        "'은행 이 너무 멀 어서 안 되 겠 네요 . 현찰 이 필요 하면 돈 을 훔치 시 어요',\n",
        "'아무래도 분실 하 ㄴ 것 같 으니 분실 신고서 를 작성 하 아야 하 겠 습니다 . 사무실 로 같이 가 시 ㄹ 까요 ?',\n",
        "'부산 에서 코로나 확진자 가 급증 하 아서 병상 이 부족하 아 지자  확진자 20명 을 대구 로 이송하 ㄴ다 .',\n",
        "'변기 가 막히 었 습니다 .',\n",
        "'그 바지 좀 보이 어 주 시 ㅂ시오 . 이거 얼마 에 사 ㄹ 수 있 는 것 이 ㅂ니까 ?',\n",
        "'비 가 오 아서 백화점 으로 가지 말 고 두타 로 가 았 으면 좋 겠 습니다 .',\n",
        "'속 이 안 좋 을 때 는 죽 이나 미음 으로 아침 을 대신 하 ㅂ니다',\n",
        "'문 대통령 은 집단 이익 에서 벗어 나 아 라고 말 하 었 다 .',\n",
        "'이것 좀 먹어 보 ㄹ 몇 일 간 의 시간 을 주 시 어요 .',\n",
        "'이날 개미군단 은 외인 의 물량 을 모두 받 아 내 었 다 .',\n",
        "'통합 우승 의 목표 를 달성하 ㄴ NC 다이노스 나성범 이 메이저리그 진출 이라는 또 다른 꿈 을 향하 어 나아가 ㄴ다 .',\n",
        "'이번 구조 조정 이 제품 을 효과 적 으로 개발 하 고 판매 하 기 위하 ㄴ 회사 의 능력 강화 조처 이 ㅁ 을 이해 하 아 주 시 리라 생각 하 ㅂ니다 .',\n",
        "'요즘 이 프로그램 녹화 하 며 많은 걸 느끼 ㄴ다 '\n",
        "'배낭 여행 은 우리 들 이 어리었을 때 허용 되 지 않 으면 우울 하 아 하 ㄴ다'\n",
        "'그 소녀 는 단지 늑대 처럼 울부짖 을 수 있 을 뿐 이 었 다']\n",
        "\n",
        "## 어절단위로 결합하여 할 경우\n",
        "\n",
        "# sen_list = [\n",
        "# '모든 액체, 젤, 에어로졸 등은 1커트 짜리 여닫이 투명 봉지 하나에 넣어야 합니다.',\n",
        "# '미안하지만 , 뒷쪽 아이들의 떠드는 소리가 커서 , 광화문으로 가고 싶은데 표를 바꾸어 주시겠어요?',\n",
        "# '은행이 너무 멀어서 안되겠네요. 현찰이 필요하면 돈을 훔치세요',\n",
        "# '아무래도 분실한 것 같으니 분실신고서를 작성해야 하겠습니다. 사무실로 같이 가실까요?',\n",
        "# '부산에서 코로나 확진자가 급증해서 병상이 부족해지자  확진자 20명을 대구로 이송한다.',\n",
        "# '변기가 막히었습니다 .',\n",
        "# '그 바지 좀 보여주십시오. 이거 얼마에 살 수 있는 것입니까?',\n",
        "# '비가 와서 백화점으로 가지 말고 두타로 갔으면 좋겠습니다 .',\n",
        "# '속이 안좋을 때는 죽이나 미음으로 아침을 대신 합니다',\n",
        "# '문 대통령은 집단이익에서 벗어나라고 말하였다.',\n",
        "# '이것 좀 먹어 볼 몇 일 간의 시간을 주세요.',\n",
        "# '이날 개미군단은 외인의 물량을 모두 받아내었다.',\n",
        "# '통합 우승의 목표를 달성한 NC 다이노스 나성범이 메이저리그 진출이라는 또다른 꿈을 향해 나아간다.',\n",
        "# '이번 구조 조정이 제품을 효과적으로 개발하고 판매하기 위한 회사의 능력 강화 조처임을 이해해 주시리라 생각합니다.',\n",
        "# '요즘 이 프로그램 녹화하며 많은 걸 느낀다'\n",
        "# '배낭 여행은 우리들이 어렸을 때 허용디지 않으면 우울 해 한다'\n",
        "# '그 소녀는 단지 늑대처럼 울부짖을 수 있을 뿐이었다']\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXgmLt8c3VeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e9340c-d8d7-4691-c268-6063d717ee67"
      },
      "source": [
        "example_idx = 0\n",
        "\n",
        "src = vars(valid_data.examples[example_idx])['ko']\n",
        "trg = vars(valid_data.examples[example_idx])['en']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['<sos>', '두어', '시간', '동안', '은', '출발', '하', '지', '않', '을', '터', '이', 'ㄴ데', '.', '<eos>']\n",
            "trg = ['<sos>', 'i', 'wo', \"n't\", 'be', 'leaving', 'for', 'another', 'couple', 'of', 'hours', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__-ATTJKy7dQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "172358c8-4a0c-4870-c03d-9461d1829c39"
      },
      "source": [
        "# 1. Packed Padded Seq\n",
        "example_idx = 4\n",
        "translation, attention = translate_sentence(sen_list[example_idx], KOREAN, ENGLISH, Seq2Seq_model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "display_attention(sen_list[example_idx], translation, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['<sos>', 'paralegals', 'are', '<unk>', 'with', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'with', '<unk>', '<unk>', '<unk>', '<unk>', 'with', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao9g0fZdFUVZ"
      },
      "source": [
        "# Visualization\n",
        "def TS_display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention[0][1], cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    \n",
        "    x_ticks = [''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>']\n",
        "    y_ticks = [''] + translation\n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo1pP7FTC6DZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "f6ce3b6d-7c13-4551-f041-bc4d305540e5"
      },
      "source": [
        "# 2. CNN\n",
        "example_idx = 4\n",
        "translation, attention = CNN_translate_sentence(sen_list[example_idx], CNN_KOREAN, CNN_ENGLISH, transformer_model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "TS_display_attention(sen_list[example_idx], translation, attention)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['sketch', 'sketch', 'geumho', 'reconfirm', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "DMqVALfiC54Z",
        "outputId": "b4423641-b22c-4148-805b-7f6bf955a683"
      },
      "source": [
        "# 3. Transformer\n",
        "example_idx = 4\n",
        "translation, attention = transformer_translate_sentence(sen_list[example_idx], CNN_KOREAN, CNN_ENGLISH, transformer_model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "TS_display_attention(sen_list[example_idx], translation, attention)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['sketch', 'sketch', 'geumho', 'reconfirm', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711', '711']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSgpTLDUhMfG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}